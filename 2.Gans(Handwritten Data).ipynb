{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_ip,train_op),(test_ip,test_op) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ip[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x15e607f9e08>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_ip[0],cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ip = (train_ip - 127.5)/127.5\n",
    "train_ip.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -0.97647059, -0.85882353, -0.85882353,\n",
       "        -0.85882353, -0.01176471,  0.06666667,  0.37254902, -0.79607843,\n",
       "         0.30196078,  1.        ,  0.9372549 , -0.00392157, -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -0.76470588, -0.71764706,\n",
       "        -0.2627451 ,  0.20784314,  0.33333333,  0.98431373,  0.98431373,\n",
       "         0.98431373,  0.98431373,  0.98431373,  0.76470588,  0.34901961,\n",
       "         0.98431373,  0.89803922,  0.52941176, -0.49803922, -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -0.61568627,  0.86666667,  0.98431373,\n",
       "         0.98431373,  0.98431373,  0.98431373,  0.98431373,  0.98431373,\n",
       "         0.98431373,  0.98431373,  0.96862745, -0.27058824, -0.35686275,\n",
       "        -0.35686275, -0.56078431, -0.69411765, -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -0.85882353,  0.71764706,  0.98431373,\n",
       "         0.98431373,  0.98431373,  0.98431373,  0.98431373,  0.55294118,\n",
       "         0.42745098,  0.9372549 ,  0.89019608, -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -0.37254902,  0.22352941,\n",
       "        -0.16078431,  0.98431373,  0.98431373,  0.60784314, -0.91372549,\n",
       "        -1.        , -0.6627451 ,  0.20784314, -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -0.89019608,\n",
       "        -0.99215686,  0.20784314,  0.98431373, -0.29411765, -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        ,  0.09019608,  0.98431373,  0.49019608, -0.98431373,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -0.91372549,  0.49019608,  0.98431373, -0.45098039,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -0.7254902 ,  0.89019608,  0.76470588,\n",
       "         0.25490196, -0.15294118, -0.99215686, -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -0.36470588,  0.88235294,\n",
       "         0.98431373,  0.98431373, -0.06666667, -0.80392157, -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -0.64705882,\n",
       "         0.45882353,  0.98431373,  0.98431373,  0.17647059, -0.78823529,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -0.8745098 , -0.27058824,  0.97647059,  0.98431373,  0.46666667,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        ,  0.95294118,  0.98431373,  0.95294118,\n",
       "        -0.49803922, -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -0.63921569,\n",
       "         0.01960784,  0.43529412,  0.98431373,  0.98431373,  0.62352941,\n",
       "        -0.98431373, -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -0.69411765,  0.16078431,  0.79607843,\n",
       "         0.98431373,  0.98431373,  0.98431373,  0.96078431,  0.42745098,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -0.81176471, -0.10588235,  0.73333333,  0.98431373,  0.98431373,\n",
       "         0.98431373,  0.98431373,  0.57647059, -0.38823529, -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -0.81960784, -0.48235294,\n",
       "         0.67058824,  0.98431373,  0.98431373,  0.98431373,  0.98431373,\n",
       "         0.55294118, -0.36470588, -0.98431373, -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -0.85882353,  0.34117647,  0.71764706,  0.98431373,\n",
       "         0.98431373,  0.98431373,  0.98431373,  0.52941176, -0.37254902,\n",
       "        -0.92941176, -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -0.56862745,\n",
       "         0.34901961,  0.77254902,  0.98431373,  0.98431373,  0.98431373,\n",
       "         0.98431373,  0.91372549,  0.04313725, -0.91372549, -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        ,  0.06666667,\n",
       "         0.98431373,  0.98431373,  0.98431373,  0.6627451 ,  0.05882353,\n",
       "         0.03529412, -0.8745098 , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ip[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x15e608b56c8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_ip[0],cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ip.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ip = train_ip.reshape(train_ip.shape[0],28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ip.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = train_ip.shape[0]\n",
    "Batch_size = 200\n",
    "train_ip = tf.data.Dataset.from_tensor_slices(train_ip).shuffle(BUFFER_SIZE).batch(Batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator():\n",
    "    model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Dense(7*7*256,input_shape=(100,),use_bias=False),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.LeakyReLU(0.2),\n",
    "            tf.keras.layers.Reshape((7,7,256)),\n",
    "            \n",
    "            tf.keras.layers.Conv2DTranspose(128,(3,3),padding=\"same\",use_bias=False),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.ReLU(),\n",
    "        \n",
    "            tf.keras.layers.Conv2DTranspose(64,(3,3),padding=\"same\",strides=(2,2),use_bias = False),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            \n",
    "            tf.keras.layers.Conv2DTranspose(1,(3,3),padding=\"same\",strides=(2,2),activation=\"tanh\")\n",
    "            \n",
    "    ])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dicriminator():\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Conv2D(126,(3,3),padding=\"same\",activation=tf.keras.layers.LeakyReLU(0.2),input_shape=(28,28,1)),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.MaxPool2D((2,2)),\n",
    "        tf.keras.layers.Conv2D(256,(3,3),padding=\"same\",activation=\"relu\"),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(64,activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(32,activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "bce = BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disc_loss(real_op,fake_op):\n",
    "    real_loss = bce(tf.ones_like(real_op),real_op)\n",
    "    fake_loss = bce(tf.zeros_like(fake_op),fake_op)\n",
    "    return real_loss + fake_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(fake_loss):\n",
    "    loss = bce(tf.ones_like(fake_loss),fake_loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 12544)             1254400   \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 12544)             50176     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 7, 7, 128)         294912    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 7, 7, 128)         512       \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 14, 14, 64)        73728     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 28, 28, 1)         577       \n",
      "=================================================================\n",
      "Total params: 1,674,561\n",
      "Trainable params: 1,649,089\n",
      "Non-trainable params: 25,472\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "desc = make_generator()\n",
    "op = desc(np.random.randn(1,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 28, 28, 1])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x15e60cb3908>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(op[0,:,:,0],cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 126)       1260      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 28, 28, 126)       504       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 126)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 256)       290560    \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 50176)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                3211328   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 3,505,765\n",
      "Trainable params: 3,505,513\n",
      "Non-trainable params: 252\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:Layer conv2d is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=921, shape=(1, 1), dtype=float32, numpy=array([[-0.09831133]], dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc = make_dicriminator()\n",
    "desc(np.random.randn(1,28,28,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_opt = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 12544)             1254400   \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 12544)             50176     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 7, 7, 128)         294912    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 7, 7, 128)         512       \n",
      "_________________________________________________________________\n",
      "re_lu_2 (ReLU)               (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTr (None, 14, 14, 64)        73728     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "re_lu_3 (ReLU)               (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTr (None, 28, 28, 1)         577       \n",
      "=================================================================\n",
      "Total params: 1,674,561\n",
      "Trainable params: 1,649,089\n",
      "Non-trainable params: 25,472\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 126)       1260      \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 28, 28, 126)       504       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 126)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 14, 14, 256)       290560    \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 50176)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                3211328   \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 3,505,765\n",
      "Trainable params: 3,505,513\n",
      "Non-trainable params: 252\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator = make_generator()\n",
    "descriminator = make_dicriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(images,epochs):\n",
    "    fake_im = np.random.randn(Batch_size,100).astype(\"float32\")\n",
    "    with tf.GradientTape() as desc_tape, tf.GradientTape() as gen_tape:\n",
    "        generated_image = generator(fake_im)\n",
    "        \n",
    "        real_op = descriminator(images)\n",
    "        fake_op = descriminator(generated_image)\n",
    "        \n",
    "        gen_loss = generator_loss(fake_op)\n",
    "        desc_los = disc_loss(real_op,fake_op)\n",
    "        \n",
    "        gradients_of_gen = gen_tape.gradient(gen_loss,generator.trainable_variables)\n",
    "        gradients_of_desc = desc_tape.gradient(desc_los,descriminator.trainable_variables)\n",
    "        \n",
    "        optimizer.apply_gradients(zip(gradients_of_desc,descriminator.trainable_variables))\n",
    "        desc_opt.apply_gradients(zip(gradients_of_gen,generator.trainable_variables))\n",
    "        print(\"gen loss\",gen_loss.numpy())\n",
    "        print(\"desc loss\",desc_los.numpy())\n",
    "        print(\"===============>\",epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset,epochs):\n",
    "    for epoch in range(epochs):\n",
    "        for image in dataset:\n",
    "            image = tf.cast(image,tf.dtypes.float32)\n",
    "            train_step(image,epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen loss 0.69225526\n",
      "desc loss 1.3580186\n",
      "===============> 0\n",
      "gen loss 0.53889775\n",
      "desc loss 0.87861073\n",
      "===============> 0\n",
      "gen loss 0.49798924\n",
      "desc loss 0.93971837\n",
      "===============> 0\n",
      "gen loss 0.5571637\n",
      "desc loss 0.8635931\n",
      "===============> 0\n",
      "gen loss 0.6625382\n",
      "desc loss 0.74812454\n",
      "===============> 0\n",
      "gen loss 0.6836702\n",
      "desc loss 0.71185297\n",
      "===============> 0\n",
      "gen loss 0.6961215\n",
      "desc loss 0.69330144\n",
      "===============> 0\n",
      "gen loss 0.6117943\n",
      "desc loss 0.782975\n",
      "===============> 0\n",
      "gen loss 0.7085261\n",
      "desc loss 0.67998874\n",
      "===============> 0\n",
      "gen loss 0.71690106\n",
      "desc loss 0.675114\n",
      "===============> 0\n",
      "gen loss 0.7426968\n",
      "desc loss 0.65279615\n",
      "===============> 0\n",
      "gen loss 0.8003237\n",
      "desc loss 0.6024475\n",
      "===============> 0\n",
      "gen loss 0.8909245\n",
      "desc loss 0.53067327\n",
      "===============> 0\n",
      "gen loss 0.9816703\n",
      "desc loss 0.47027922\n",
      "===============> 0\n",
      "gen loss 1.1716706\n",
      "desc loss 0.37264994\n",
      "===============> 0\n",
      "gen loss 1.3646878\n",
      "desc loss 0.299648\n",
      "===============> 0\n",
      "gen loss 1.6620206\n",
      "desc loss 0.21755384\n",
      "===============> 0\n",
      "gen loss 2.0965807\n",
      "desc loss 0.14061914\n",
      "===============> 0\n",
      "gen loss 2.6529477\n",
      "desc loss 0.08323296\n",
      "===============> 0\n",
      "gen loss 3.2386827\n",
      "desc loss 0.049128827\n",
      "===============> 0\n",
      "gen loss 4.301045\n",
      "desc loss 0.03945984\n",
      "===============> 0\n",
      "gen loss 3.916385\n",
      "desc loss 0.03583266\n",
      "===============> 0\n",
      "gen loss 5.7394423\n",
      "desc loss 0.028402776\n",
      "===============> 0\n",
      "gen loss 6.5134034\n",
      "desc loss 0.025663111\n",
      "===============> 0\n",
      "gen loss 5.1155653\n",
      "desc loss 0.03768561\n",
      "===============> 0\n",
      "gen loss 6.158092\n",
      "desc loss 0.062221162\n",
      "===============> 0\n",
      "gen loss 8.055981\n",
      "desc loss 0.048573144\n",
      "===============> 0\n",
      "gen loss 9.943768\n",
      "desc loss 0.06089896\n",
      "===============> 0\n",
      "gen loss 8.178805\n",
      "desc loss 0.026089193\n",
      "===============> 0\n",
      "gen loss 6.226004\n",
      "desc loss 0.042897597\n",
      "===============> 0\n",
      "gen loss 6.3239985\n",
      "desc loss 0.019778874\n",
      "===============> 0\n",
      "gen loss 7.260099\n",
      "desc loss 0.019479822\n",
      "===============> 0\n",
      "gen loss 6.008142\n",
      "desc loss 0.022043377\n",
      "===============> 0\n",
      "gen loss 4.339425\n",
      "desc loss 0.038137108\n",
      "===============> 0\n",
      "gen loss 14.338166\n",
      "desc loss 1.3126764\n",
      "===============> 0\n",
      "gen loss 1.1380298\n",
      "desc loss 2.7474372\n",
      "===============> 0\n",
      "gen loss 8.568127\n",
      "desc loss 0.022105357\n",
      "===============> 0\n",
      "gen loss 16.66146\n",
      "desc loss 0.39384988\n",
      "===============> 0\n",
      "gen loss 17.293179\n",
      "desc loss 0.95186365\n",
      "===============> 0\n",
      "gen loss 17.180763\n",
      "desc loss 1.0014465\n",
      "===============> 0\n",
      "gen loss 15.978961\n",
      "desc loss 0.9229938\n",
      "===============> 0\n",
      "gen loss 14.254743\n",
      "desc loss 0.8308954\n",
      "===============> 0\n",
      "gen loss 12.924331\n",
      "desc loss 0.93271685\n",
      "===============> 0\n",
      "gen loss 12.418081\n",
      "desc loss 0.10802546\n",
      "===============> 0\n",
      "gen loss 14.2031765\n",
      "desc loss 0.010796675\n",
      "===============> 0\n",
      "gen loss 15.272893\n",
      "desc loss 0.12424302\n",
      "===============> 0\n",
      "gen loss 14.587976\n",
      "desc loss 0.06886224\n",
      "===============> 0\n",
      "gen loss 12.687279\n",
      "desc loss 0.056090143\n",
      "===============> 0\n",
      "gen loss 10.746797\n",
      "desc loss 0.026543206\n",
      "===============> 0\n",
      "gen loss 7.735857\n",
      "desc loss 0.034882393\n",
      "===============> 0\n",
      "gen loss 5.784953\n",
      "desc loss 0.20538755\n",
      "===============> 0\n",
      "gen loss 9.64273\n",
      "desc loss 0.02617197\n",
      "===============> 0\n",
      "gen loss 11.777509\n",
      "desc loss 0.3541379\n",
      "===============> 0\n",
      "gen loss 10.6289425\n",
      "desc loss 0.2096729\n",
      "===============> 0\n",
      "gen loss 8.392966\n",
      "desc loss 0.012595523\n",
      "===============> 0\n",
      "gen loss 6.833795\n",
      "desc loss 0.1297547\n",
      "===============> 0\n",
      "gen loss 6.8017445\n",
      "desc loss 0.10383288\n",
      "===============> 0\n",
      "gen loss 8.068291\n",
      "desc loss 0.029144526\n",
      "===============> 0\n",
      "gen loss 9.514388\n",
      "desc loss 0.011572676\n",
      "===============> 0\n",
      "gen loss 10.760271\n",
      "desc loss 0.001388818\n",
      "===============> 0\n",
      "gen loss 11.474143\n",
      "desc loss 0.021212434\n",
      "===============> 0\n",
      "gen loss 12.06748\n",
      "desc loss 0.016685879\n",
      "===============> 0\n",
      "gen loss 12.06448\n",
      "desc loss 0.019490773\n",
      "===============> 0\n",
      "gen loss 11.35326\n",
      "desc loss 0.032266565\n",
      "===============> 0\n",
      "gen loss 10.462869\n",
      "desc loss 0.13446122\n",
      "===============> 0\n",
      "gen loss 9.671098\n",
      "desc loss 0.25228152\n",
      "===============> 0\n",
      "gen loss 10.233515\n",
      "desc loss 0.16165525\n",
      "===============> 0\n",
      "gen loss 11.119751\n",
      "desc loss 0.6635532\n",
      "===============> 0\n",
      "gen loss 8.610386\n",
      "desc loss 0.90262246\n",
      "===============> 0\n",
      "gen loss 8.685698\n",
      "desc loss 1.0192783\n",
      "===============> 0\n",
      "gen loss 9.292435\n",
      "desc loss 1.1807305\n",
      "===============> 0\n",
      "gen loss 5.9631667\n",
      "desc loss 1.7111416\n",
      "===============> 0\n",
      "gen loss 9.061085\n",
      "desc loss 0.8588158\n",
      "===============> 0\n",
      "gen loss 10.24626\n",
      "desc loss 0.552447\n",
      "===============> 0\n",
      "gen loss 9.041509\n",
      "desc loss 0.1787281\n",
      "===============> 0\n",
      "gen loss 6.51534\n",
      "desc loss 0.95529854\n",
      "===============> 0\n",
      "gen loss 8.346479\n",
      "desc loss 0.4148798\n",
      "===============> 0\n",
      "gen loss 11.742602\n",
      "desc loss 1.6366681\n",
      "===============> 0\n",
      "gen loss 6.5720606\n",
      "desc loss 1.1665354\n",
      "===============> 0\n",
      "gen loss 3.991029\n",
      "desc loss 1.7889596\n",
      "===============> 0\n",
      "gen loss 4.625117\n",
      "desc loss 0.49543515\n",
      "===============> 0\n",
      "gen loss 6.686463\n",
      "desc loss 1.0557977\n",
      "===============> 0\n",
      "gen loss 5.6841755\n",
      "desc loss 0.22485481\n",
      "===============> 0\n",
      "gen loss 3.7294395\n",
      "desc loss 0.1452391\n",
      "===============> 0\n",
      "gen loss 3.1965292\n",
      "desc loss 0.18322724\n",
      "===============> 0\n",
      "gen loss 3.5991204\n",
      "desc loss 0.089080356\n",
      "===============> 0\n",
      "gen loss 4.749725\n",
      "desc loss 0.026783593\n",
      "===============> 0\n",
      "gen loss 5.6109133\n",
      "desc loss 0.011200951\n",
      "===============> 0\n",
      "gen loss 7.005825\n",
      "desc loss 0.025627645\n",
      "===============> 0\n",
      "gen loss 7.658646\n",
      "desc loss 0.01927207\n",
      "===============> 0\n",
      "gen loss 8.195067\n",
      "desc loss 0.014896035\n",
      "===============> 0\n",
      "gen loss 8.185744\n",
      "desc loss 0.054855216\n",
      "===============> 0\n",
      "gen loss 8.385867\n",
      "desc loss 0.039494097\n",
      "===============> 0\n",
      "gen loss 8.364088\n",
      "desc loss 0.010159602\n",
      "===============> 0\n",
      "gen loss 8.209217\n",
      "desc loss 0.018374357\n",
      "===============> 0\n",
      "gen loss 7.79838\n",
      "desc loss 0.012020683\n",
      "===============> 0\n",
      "gen loss 7.1458826\n",
      "desc loss 0.04368346\n",
      "===============> 0\n",
      "gen loss 6.5403423\n",
      "desc loss 0.065966\n",
      "===============> 0\n",
      "gen loss 5.854508\n",
      "desc loss 0.12413993\n",
      "===============> 0\n",
      "gen loss 5.9099483\n",
      "desc loss 0.14535597\n",
      "===============> 0\n",
      "gen loss 6.437786\n",
      "desc loss 0.09019232\n",
      "===============> 0\n",
      "gen loss 6.8990993\n",
      "desc loss 0.098191366\n",
      "===============> 0\n",
      "gen loss 6.5067616\n",
      "desc loss 0.11908626\n",
      "===============> 0\n",
      "gen loss 5.5885158\n",
      "desc loss 0.23061019\n",
      "===============> 0\n",
      "gen loss 4.113779\n",
      "desc loss 0.4325554\n",
      "===============> 0\n",
      "gen loss 3.7907019\n",
      "desc loss 0.469009\n",
      "===============> 0\n",
      "gen loss 5.985586\n",
      "desc loss 0.86104625\n",
      "===============> 0\n",
      "gen loss 5.465448\n",
      "desc loss 0.6346972\n",
      "===============> 0\n",
      "gen loss 4.719071\n",
      "desc loss 0.78152686\n",
      "===============> 0\n",
      "gen loss 3.8235662\n",
      "desc loss 0.70520794\n",
      "===============> 0\n",
      "gen loss 4.3533845\n",
      "desc loss 0.5610199\n",
      "===============> 0\n",
      "gen loss 5.869894\n",
      "desc loss 0.62755704\n",
      "===============> 0\n",
      "gen loss 7.499256\n",
      "desc loss 0.32549497\n",
      "===============> 0\n",
      "gen loss 8.718827\n",
      "desc loss 0.10934731\n",
      "===============> 0\n",
      "gen loss 9.03768\n",
      "desc loss 0.17892739\n",
      "===============> 0\n",
      "gen loss 9.475406\n",
      "desc loss 0.09020384\n",
      "===============> 0\n",
      "gen loss 9.218479\n",
      "desc loss 0.16908333\n",
      "===============> 0\n",
      "gen loss 10.1338005\n",
      "desc loss 0.09950653\n",
      "===============> 0\n",
      "gen loss 10.188936\n",
      "desc loss 0.2404501\n",
      "===============> 0\n",
      "gen loss 8.955131\n",
      "desc loss 0.21399267\n",
      "===============> 0\n",
      "gen loss 6.2834034\n",
      "desc loss 0.50445384\n",
      "===============> 0\n",
      "gen loss 5.802329\n",
      "desc loss 0.63552386\n",
      "===============> 0\n",
      "gen loss 6.902104\n",
      "desc loss 1.102014\n",
      "===============> 0\n",
      "gen loss 5.3090205\n",
      "desc loss 1.0289606\n",
      "===============> 0\n",
      "gen loss 2.5299227\n",
      "desc loss 1.2307173\n",
      "===============> 0\n",
      "gen loss 2.7168012\n",
      "desc loss 1.2155104\n",
      "===============> 0\n",
      "gen loss 3.8212626\n",
      "desc loss 1.1527475\n",
      "===============> 0\n",
      "gen loss 2.6994905\n",
      "desc loss 0.6819976\n",
      "===============> 0\n",
      "gen loss 1.285758\n",
      "desc loss 0.8025764\n",
      "===============> 0\n",
      "gen loss 2.6858244\n",
      "desc loss 0.47458312\n",
      "===============> 0\n",
      "gen loss 3.2021792\n",
      "desc loss 0.47490257\n",
      "===============> 0\n",
      "gen loss 3.0377455\n",
      "desc loss 0.3122076\n",
      "===============> 0\n",
      "gen loss 2.5051508\n",
      "desc loss 0.3616237\n",
      "===============> 0\n",
      "gen loss 3.0890353\n",
      "desc loss 0.26958653\n",
      "===============> 0\n",
      "gen loss 4.0444803\n",
      "desc loss 0.3418901\n",
      "===============> 0\n",
      "gen loss 3.7530494\n",
      "desc loss 0.26230264\n",
      "===============> 0\n",
      "gen loss 3.2928765\n",
      "desc loss 0.26746562\n",
      "===============> 0\n",
      "gen loss 3.7983036\n",
      "desc loss 0.20451099\n",
      "===============> 0\n",
      "gen loss 3.96092\n",
      "desc loss 0.23468329\n",
      "===============> 0\n",
      "gen loss 4.6843348\n",
      "desc loss 0.28075796\n",
      "===============> 0\n",
      "gen loss 4.227436\n",
      "desc loss 0.22562587\n",
      "===============> 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen loss 3.6723523\n",
      "desc loss 0.314309\n",
      "===============> 0\n",
      "gen loss 4.076261\n",
      "desc loss 0.244965\n",
      "===============> 0\n",
      "gen loss 4.427483\n",
      "desc loss 0.24929321\n",
      "===============> 0\n",
      "gen loss 4.5080624\n",
      "desc loss 0.25814587\n",
      "===============> 0\n",
      "gen loss 4.070491\n",
      "desc loss 0.2657851\n",
      "===============> 0\n",
      "gen loss 5.058214\n",
      "desc loss 0.3687695\n",
      "===============> 0\n",
      "gen loss 4.2055597\n",
      "desc loss 0.34615082\n",
      "===============> 0\n",
      "gen loss 2.89495\n",
      "desc loss 0.4484269\n",
      "===============> 0\n",
      "gen loss 4.475904\n",
      "desc loss 0.262586\n",
      "===============> 0\n",
      "gen loss 5.0968895\n",
      "desc loss 0.3132568\n",
      "===============> 0\n",
      "gen loss 4.261515\n",
      "desc loss 0.32738125\n",
      "===============> 0\n",
      "gen loss 3.8049762\n",
      "desc loss 0.2496712\n",
      "===============> 0\n",
      "gen loss 3.3177688\n",
      "desc loss 0.37283808\n",
      "===============> 0\n",
      "gen loss 4.395745\n",
      "desc loss 0.2547687\n",
      "===============> 0\n",
      "gen loss 4.4845295\n",
      "desc loss 0.32459483\n",
      "===============> 0\n",
      "gen loss 4.4005527\n",
      "desc loss 0.25320566\n",
      "===============> 0\n",
      "gen loss 3.8473322\n",
      "desc loss 0.29591733\n",
      "===============> 0\n",
      "gen loss 4.095193\n",
      "desc loss 0.25143743\n",
      "===============> 0\n",
      "gen loss 4.8019624\n",
      "desc loss 0.27908275\n",
      "===============> 0\n",
      "gen loss 5.150558\n",
      "desc loss 0.23876205\n",
      "===============> 0\n",
      "gen loss 5.3925853\n",
      "desc loss 0.19330695\n",
      "===============> 0\n",
      "gen loss 4.1789527\n",
      "desc loss 0.23906457\n",
      "===============> 0\n",
      "gen loss 4.732647\n",
      "desc loss 0.17750473\n",
      "===============> 0\n",
      "gen loss 5.4695897\n",
      "desc loss 0.14571273\n",
      "===============> 0\n",
      "gen loss 5.870077\n",
      "desc loss 0.15195\n",
      "===============> 0\n",
      "gen loss 5.0272875\n",
      "desc loss 0.095228404\n",
      "===============> 0\n",
      "gen loss 4.827031\n",
      "desc loss 0.097208984\n",
      "===============> 0\n",
      "gen loss 4.7713995\n",
      "desc loss 0.14949696\n",
      "===============> 0\n",
      "gen loss 5.6339183\n",
      "desc loss 0.0953102\n",
      "===============> 0\n",
      "gen loss 4.8768544\n",
      "desc loss 0.17111106\n",
      "===============> 0\n",
      "gen loss 4.054023\n",
      "desc loss 0.17376596\n",
      "===============> 0\n",
      "gen loss 4.708823\n",
      "desc loss 0.16706698\n",
      "===============> 0\n",
      "gen loss 5.0390606\n",
      "desc loss 0.15809177\n",
      "===============> 0\n",
      "gen loss 3.9098923\n",
      "desc loss 0.16582574\n",
      "===============> 0\n",
      "gen loss 4.0481696\n",
      "desc loss 0.17551589\n",
      "===============> 0\n",
      "gen loss 5.0725727\n",
      "desc loss 0.3444489\n",
      "===============> 0\n",
      "gen loss 3.3349195\n",
      "desc loss 0.34662247\n",
      "===============> 0\n",
      "gen loss 4.2009444\n",
      "desc loss 0.19414312\n",
      "===============> 0\n",
      "gen loss 4.6880965\n",
      "desc loss 0.1444077\n",
      "===============> 0\n",
      "gen loss 4.2482567\n",
      "desc loss 0.26396987\n",
      "===============> 0\n",
      "gen loss 2.349507\n",
      "desc loss 0.33917478\n",
      "===============> 0\n",
      "gen loss 5.240703\n",
      "desc loss 0.21654963\n",
      "===============> 0\n",
      "gen loss 5.8960204\n",
      "desc loss 0.37646064\n",
      "===============> 0\n",
      "gen loss 3.3458936\n",
      "desc loss 0.14718139\n",
      "===============> 0\n",
      "gen loss 2.1612563\n",
      "desc loss 0.35161927\n",
      "===============> 0\n",
      "gen loss 4.956147\n",
      "desc loss 0.13600683\n",
      "===============> 0\n",
      "gen loss 6.403863\n",
      "desc loss 0.18593197\n",
      "===============> 0\n",
      "gen loss 6.215823\n",
      "desc loss 0.18533675\n",
      "===============> 0\n",
      "gen loss 4.683699\n",
      "desc loss 0.09803178\n",
      "===============> 0\n",
      "gen loss 3.3886406\n",
      "desc loss 0.15601723\n",
      "===============> 0\n",
      "gen loss 3.8703103\n",
      "desc loss 0.12081207\n",
      "===============> 0\n",
      "gen loss 4.751471\n",
      "desc loss 0.093035415\n",
      "===============> 0\n",
      "gen loss 6.222877\n",
      "desc loss 0.18315628\n",
      "===============> 0\n",
      "gen loss 6.188391\n",
      "desc loss 0.14532891\n",
      "===============> 0\n",
      "gen loss 5.7929616\n",
      "desc loss 0.117845416\n",
      "===============> 0\n",
      "gen loss 4.4634438\n",
      "desc loss 0.15783381\n",
      "===============> 0\n",
      "gen loss 4.3075476\n",
      "desc loss 0.16290164\n",
      "===============> 0\n",
      "gen loss 5.3865685\n",
      "desc loss 0.115637764\n",
      "===============> 0\n",
      "gen loss 6.0099306\n",
      "desc loss 0.15065297\n",
      "===============> 0\n",
      "gen loss 6.2652965\n",
      "desc loss 0.13032353\n",
      "===============> 0\n",
      "gen loss 5.4340096\n",
      "desc loss 0.11473383\n",
      "===============> 0\n",
      "gen loss 4.317147\n",
      "desc loss 0.11618311\n",
      "===============> 0\n",
      "gen loss 4.3134327\n",
      "desc loss 0.11298578\n",
      "===============> 0\n",
      "gen loss 5.2087083\n",
      "desc loss 0.114378035\n",
      "===============> 0\n",
      "gen loss 5.833723\n",
      "desc loss 0.18438855\n",
      "===============> 0\n",
      "gen loss 4.9488487\n",
      "desc loss 0.13301556\n",
      "===============> 0\n",
      "gen loss 3.6446373\n",
      "desc loss 0.2846474\n",
      "===============> 0\n",
      "gen loss 4.660314\n",
      "desc loss 0.2541105\n",
      "===============> 0\n",
      "gen loss 5.3648224\n",
      "desc loss 0.31723142\n",
      "===============> 0\n",
      "gen loss 3.9653943\n",
      "desc loss 0.27182394\n",
      "===============> 0\n",
      "gen loss 3.2006605\n",
      "desc loss 0.33578664\n",
      "===============> 0\n",
      "gen loss 5.652979\n",
      "desc loss 0.24362431\n",
      "===============> 0\n",
      "gen loss 5.3049335\n",
      "desc loss 0.35910907\n",
      "===============> 0\n",
      "gen loss 2.7608247\n",
      "desc loss 0.47502387\n",
      "===============> 0\n",
      "gen loss 4.762559\n",
      "desc loss 0.21245325\n",
      "===============> 0\n",
      "gen loss 6.164446\n",
      "desc loss 0.30731383\n",
      "===============> 0\n",
      "gen loss 4.906061\n",
      "desc loss 0.13184564\n",
      "===============> 0\n",
      "gen loss 3.4531872\n",
      "desc loss 0.30034366\n",
      "===============> 0\n",
      "gen loss 5.137605\n",
      "desc loss 0.20648073\n",
      "===============> 0\n",
      "gen loss 5.5644994\n",
      "desc loss 0.298762\n",
      "===============> 0\n",
      "gen loss 4.1550417\n",
      "desc loss 0.24848223\n",
      "===============> 0\n",
      "gen loss 4.1217456\n",
      "desc loss 0.28530228\n",
      "===============> 0\n",
      "gen loss 4.763842\n",
      "desc loss 0.28570533\n",
      "===============> 0\n",
      "gen loss 5.0538116\n",
      "desc loss 0.30937088\n",
      "===============> 0\n",
      "gen loss 3.907439\n",
      "desc loss 0.24454536\n",
      "===============> 0\n",
      "gen loss 4.128004\n",
      "desc loss 0.27297282\n",
      "===============> 0\n",
      "gen loss 4.2365456\n",
      "desc loss 0.37032863\n",
      "===============> 0\n",
      "gen loss 3.664967\n",
      "desc loss 0.37236625\n",
      "===============> 0\n",
      "gen loss 3.5075262\n",
      "desc loss 0.38468993\n",
      "===============> 0\n",
      "gen loss 3.955764\n",
      "desc loss 0.3649658\n",
      "===============> 0\n",
      "gen loss 3.7847214\n",
      "desc loss 0.30552077\n",
      "===============> 0\n",
      "gen loss 4.2526507\n",
      "desc loss 0.33594644\n",
      "===============> 0\n",
      "gen loss 3.7275007\n",
      "desc loss 0.33730644\n",
      "===============> 0\n",
      "gen loss 3.3987863\n",
      "desc loss 0.3219771\n",
      "===============> 0\n",
      "gen loss 4.497292\n",
      "desc loss 0.31829235\n",
      "===============> 0\n",
      "gen loss 2.9322672\n",
      "desc loss 0.26741278\n",
      "===============> 0\n",
      "gen loss 3.997178\n",
      "desc loss 0.25106004\n",
      "===============> 0\n",
      "gen loss 4.571203\n",
      "desc loss 0.24269478\n",
      "===============> 0\n",
      "gen loss 4.0355573\n",
      "desc loss 0.26062942\n",
      "===============> 0\n",
      "gen loss 3.7850714\n",
      "desc loss 0.26767907\n",
      "===============> 0\n",
      "gen loss 4.4571767\n",
      "desc loss 0.25109482\n",
      "===============> 0\n",
      "gen loss 4.5834713\n",
      "desc loss 0.26858574\n",
      "===============> 0\n",
      "gen loss 3.5405383\n",
      "desc loss 0.30806094\n",
      "===============> 0\n",
      "gen loss 3.2638342\n",
      "desc loss 0.24911925\n",
      "===============> 0\n",
      "gen loss 4.3422203\n",
      "desc loss 0.25610277\n",
      "===============> 0\n",
      "gen loss 4.004602\n",
      "desc loss 0.29349214\n",
      "===============> 0\n",
      "gen loss 3.0718904\n",
      "desc loss 0.35350373\n",
      "===============> 0\n",
      "gen loss 4.1126866\n",
      "desc loss 0.2782667\n",
      "===============> 0\n",
      "gen loss 4.2937407\n",
      "desc loss 0.30537903\n",
      "===============> 0\n",
      "gen loss 3.2703216\n",
      "desc loss 0.32574278\n",
      "===============> 0\n",
      "gen loss 3.7766104\n",
      "desc loss 0.30465513\n",
      "===============> 0\n",
      "gen loss 4.8510585\n",
      "desc loss 0.25114208\n",
      "===============> 0\n",
      "gen loss 4.682907\n",
      "desc loss 0.3166408\n",
      "===============> 0\n",
      "gen loss 3.0600328\n",
      "desc loss 0.4698702\n",
      "===============> 0\n",
      "gen loss 4.950771\n",
      "desc loss 0.4569735\n",
      "===============> 0\n",
      "gen loss 4.9563375\n",
      "desc loss 0.37375516\n",
      "===============> 0\n",
      "gen loss 3.0060766\n",
      "desc loss 0.41670707\n",
      "===============> 0\n",
      "gen loss 3.4981818\n",
      "desc loss 0.27441394\n",
      "===============> 0\n",
      "gen loss 4.8405957\n",
      "desc loss 0.50445986\n",
      "===============> 0\n",
      "gen loss 3.4997256\n",
      "desc loss 0.32855964\n",
      "===============> 0\n",
      "gen loss 2.3295422\n",
      "desc loss 0.5675216\n",
      "===============> 0\n",
      "gen loss 4.845831\n",
      "desc loss 0.50214195\n",
      "===============> 0\n",
      "gen loss 4.473728\n",
      "desc loss 0.40948468\n",
      "===============> 0\n",
      "gen loss 1.6662976\n",
      "desc loss 0.67870945\n",
      "===============> 0\n",
      "gen loss 4.442529\n",
      "desc loss 0.26763067\n",
      "===============> 0\n",
      "gen loss 4.9792614\n",
      "desc loss 0.39264524\n",
      "===============> 0\n",
      "gen loss 3.1990173\n",
      "desc loss 0.30517533\n",
      "===============> 0\n",
      "gen loss 1.5473953\n",
      "desc loss 0.67586005\n",
      "===============> 0\n",
      "gen loss 5.3608685\n",
      "desc loss 0.6316616\n",
      "===============> 0\n",
      "gen loss 5.4725575\n",
      "desc loss 0.62573266\n",
      "===============> 0\n",
      "gen loss 1.5753168\n",
      "desc loss 0.96953046\n",
      "===============> 0\n",
      "gen loss 4.794708\n",
      "desc loss 0.72656584\n",
      "===============> 0\n",
      "gen loss 4.714195\n",
      "desc loss 0.54890615\n",
      "===============> 0\n",
      "gen loss 2.3551981\n",
      "desc loss 0.7394877\n",
      "===============> 0\n",
      "gen loss 6.7162657\n",
      "desc loss 0.539153\n",
      "===============> 0\n",
      "gen loss 7.5789275\n",
      "desc loss 0.5343633\n",
      "===============> 0\n",
      "gen loss 4.192716\n",
      "desc loss 0.1567458\n",
      "===============> 0\n",
      "gen loss 3.4190474\n",
      "desc loss 0.24431084\n",
      "===============> 0\n",
      "gen loss 6.430461\n",
      "desc loss 0.030208899\n",
      "===============> 0\n",
      "gen loss 8.292415\n",
      "desc loss 0.06650009\n",
      "===============> 0\n",
      "gen loss 8.588327\n",
      "desc loss 0.056713797\n",
      "===============> 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen loss 8.3384695\n",
      "desc loss 0.033161476\n",
      "===============> 0\n",
      "gen loss 7.12985\n",
      "desc loss 0.028555542\n",
      "===============> 0\n",
      "gen loss 5.6095805\n",
      "desc loss 0.10298592\n",
      "===============> 0\n",
      "gen loss 4.42713\n",
      "desc loss 0.30972445\n",
      "===============> 0\n",
      "gen loss 5.1548066\n",
      "desc loss 0.13477094\n",
      "===============> 0\n",
      "gen loss 5.9740834\n",
      "desc loss 0.22989418\n",
      "===============> 0\n",
      "gen loss 5.664848\n",
      "desc loss 0.26841646\n",
      "===============> 0\n",
      "gen loss 3.8126223\n",
      "desc loss 0.22876772\n",
      "===============> 0\n",
      "gen loss 2.6470642\n",
      "desc loss 0.3403906\n",
      "===============> 0\n",
      "gen loss 3.2495844\n",
      "desc loss 0.19139458\n",
      "===============> 0\n",
      "gen loss 4.241814\n",
      "desc loss 0.21879813\n",
      "===============> 0\n",
      "gen loss 4.6663074\n",
      "desc loss 0.18116723\n",
      "===============> 0\n",
      "gen loss 4.4510937\n",
      "desc loss 0.14990598\n",
      "===============> 0\n",
      "gen loss 3.8412445\n",
      "desc loss 0.036619667\n",
      "===============> 0\n",
      "gen loss 3.5545287\n",
      "desc loss 0.085887805\n",
      "===============> 0\n",
      "gen loss 3.9451556\n",
      "desc loss 0.0413687\n",
      "===============> 0\n",
      "gen loss 4.5211115\n",
      "desc loss 0.027904013\n",
      "===============> 0\n",
      "gen loss 5.1619453\n",
      "desc loss 0.0172323\n",
      "===============> 0\n",
      "gen loss 5.8192487\n",
      "desc loss 0.038619984\n",
      "===============> 1\n",
      "gen loss 6.5338354\n",
      "desc loss 0.016538398\n",
      "===============> 1\n",
      "gen loss 7.204557\n",
      "desc loss 0.03069453\n",
      "===============> 1\n",
      "gen loss 7.7301426\n",
      "desc loss 0.044206478\n",
      "===============> 1\n",
      "gen loss 7.6978908\n",
      "desc loss 0.023199636\n",
      "===============> 1\n",
      "gen loss 7.8094482\n",
      "desc loss 0.045838334\n",
      "===============> 1\n",
      "gen loss 7.7722235\n",
      "desc loss 0.108851686\n",
      "===============> 1\n",
      "gen loss 8.924535\n",
      "desc loss 0.13829494\n",
      "===============> 1\n",
      "gen loss 9.492251\n",
      "desc loss 0.1664927\n",
      "===============> 1\n",
      "gen loss 11.362621\n",
      "desc loss 0.45253658\n",
      "===============> 1\n",
      "gen loss 9.256682\n",
      "desc loss 0.547842\n",
      "===============> 1\n",
      "gen loss 6.9585476\n",
      "desc loss 0.75286067\n",
      "===============> 1\n",
      "gen loss 7.099697\n",
      "desc loss 0.93459153\n",
      "===============> 1\n",
      "gen loss 8.618129\n",
      "desc loss 1.2641441\n",
      "===============> 1\n",
      "gen loss 7.241573\n",
      "desc loss 1.105973\n",
      "===============> 1\n",
      "gen loss 3.059273\n",
      "desc loss 1.9362636\n",
      "===============> 1\n",
      "gen loss 4.3191204\n",
      "desc loss 1.5944078\n",
      "===============> 1\n",
      "gen loss 6.4489174\n",
      "desc loss 2.336898\n",
      "===============> 1\n",
      "gen loss 2.9238732\n",
      "desc loss 1.7367309\n",
      "===============> 1\n",
      "gen loss 2.4514863\n",
      "desc loss 1.7453365\n",
      "===============> 1\n",
      "gen loss 4.5713005\n",
      "desc loss 0.7792718\n",
      "===============> 1\n",
      "gen loss 5.8804383\n",
      "desc loss 1.0848651\n",
      "===============> 1\n",
      "gen loss 4.2372074\n",
      "desc loss 0.30952716\n",
      "===============> 1\n",
      "gen loss 2.7480886\n",
      "desc loss 0.44785166\n",
      "===============> 1\n",
      "gen loss 3.1569848\n",
      "desc loss 0.30890784\n",
      "===============> 1\n",
      "gen loss 4.2579017\n",
      "desc loss 0.20010895\n",
      "===============> 1\n",
      "gen loss 5.648976\n",
      "desc loss 0.28249177\n",
      "===============> 1\n",
      "gen loss 6.0373554\n",
      "desc loss 0.34554008\n",
      "===============> 1\n",
      "gen loss 5.6246605\n",
      "desc loss 0.37521964\n",
      "===============> 1\n",
      "gen loss 4.2204475\n",
      "desc loss 0.37175584\n",
      "===============> 1\n",
      "gen loss 3.6847708\n",
      "desc loss 0.4080042\n",
      "===============> 1\n",
      "gen loss 3.547091\n",
      "desc loss 0.426397\n",
      "===============> 1\n",
      "gen loss 4.3787503\n",
      "desc loss 0.45852184\n",
      "===============> 1\n",
      "gen loss 5.464724\n",
      "desc loss 0.32755703\n",
      "===============> 1\n",
      "gen loss 5.617922\n",
      "desc loss 0.40836307\n",
      "===============> 1\n",
      "gen loss 5.4687505\n",
      "desc loss 0.4480192\n",
      "===============> 1\n",
      "gen loss 5.598932\n",
      "desc loss 0.6164446\n",
      "===============> 1\n",
      "gen loss 4.2836246\n",
      "desc loss 0.5070634\n",
      "===============> 1\n",
      "gen loss 3.1009345\n",
      "desc loss 0.76109284\n",
      "===============> 1\n",
      "gen loss 2.9002578\n",
      "desc loss 0.7110801\n",
      "===============> 1\n",
      "gen loss 3.1462722\n",
      "desc loss 0.55397326\n",
      "===============> 1\n",
      "gen loss 4.055685\n",
      "desc loss 0.6464933\n",
      "===============> 1\n",
      "gen loss 3.7870934\n",
      "desc loss 0.62032455\n",
      "===============> 1\n",
      "gen loss 4.6465416\n",
      "desc loss 0.652322\n",
      "===============> 1\n",
      "gen loss 3.5819335\n",
      "desc loss 0.6973034\n",
      "===============> 1\n",
      "gen loss 2.6914556\n",
      "desc loss 0.5518122\n",
      "===============> 1\n",
      "gen loss 2.2457266\n",
      "desc loss 0.57462674\n",
      "===============> 1\n",
      "gen loss 2.570947\n",
      "desc loss 0.46999946\n",
      "===============> 1\n",
      "gen loss 3.0420218\n",
      "desc loss 0.39666897\n",
      "===============> 1\n",
      "gen loss 3.7889948\n",
      "desc loss 0.2893851\n",
      "===============> 1\n",
      "gen loss 4.068736\n",
      "desc loss 0.37497488\n",
      "===============> 1\n",
      "gen loss 4.3839984\n",
      "desc loss 0.371927\n",
      "===============> 1\n",
      "gen loss 3.9811797\n",
      "desc loss 0.22686881\n",
      "===============> 1\n",
      "gen loss 3.7134295\n",
      "desc loss 0.27088597\n",
      "===============> 1\n",
      "gen loss 3.4880478\n",
      "desc loss 0.36058915\n",
      "===============> 1\n",
      "gen loss 3.6785302\n",
      "desc loss 0.24452825\n",
      "===============> 1\n",
      "gen loss 4.4315724\n",
      "desc loss 0.18970525\n",
      "===============> 1\n",
      "gen loss 4.6840906\n",
      "desc loss 0.27016717\n",
      "===============> 1\n",
      "gen loss 4.8364515\n",
      "desc loss 0.29343164\n",
      "===============> 1\n",
      "gen loss 5.355101\n",
      "desc loss 0.31182453\n",
      "===============> 1\n",
      "gen loss 5.089986\n",
      "desc loss 0.32864755\n",
      "===============> 1\n",
      "gen loss 4.437125\n",
      "desc loss 0.39262354\n",
      "===============> 1\n",
      "gen loss 4.867587\n",
      "desc loss 0.3192957\n",
      "===============> 1\n",
      "gen loss 4.6494703\n",
      "desc loss 0.4163757\n",
      "===============> 1\n",
      "gen loss 4.9400663\n",
      "desc loss 0.4194895\n",
      "===============> 1\n",
      "gen loss 5.348107\n",
      "desc loss 0.37627178\n",
      "===============> 1\n",
      "gen loss 4.4733534\n",
      "desc loss 0.5433365\n",
      "===============> 1\n",
      "gen loss 4.4765086\n",
      "desc loss 0.51838374\n",
      "===============> 1\n",
      "gen loss 4.655507\n",
      "desc loss 0.6010761\n",
      "===============> 1\n",
      "gen loss 4.2509594\n",
      "desc loss 0.5696875\n",
      "===============> 1\n",
      "gen loss 3.8444304\n",
      "desc loss 0.5337709\n",
      "===============> 1\n",
      "gen loss 3.3459039\n",
      "desc loss 0.609396\n",
      "===============> 1\n",
      "gen loss 4.0844417\n",
      "desc loss 0.4973124\n",
      "===============> 1\n",
      "gen loss 3.7542815\n",
      "desc loss 0.6655719\n",
      "===============> 1\n",
      "gen loss 3.2563136\n",
      "desc loss 0.70332634\n",
      "===============> 1\n",
      "gen loss 2.3862605\n",
      "desc loss 0.6456697\n",
      "===============> 1\n",
      "gen loss 2.6125202\n",
      "desc loss 0.64849377\n",
      "===============> 1\n",
      "gen loss 2.8286915\n",
      "desc loss 0.6669422\n",
      "===============> 1\n",
      "gen loss 2.4347067\n",
      "desc loss 0.5949862\n",
      "===============> 1\n",
      "gen loss 1.9314743\n",
      "desc loss 0.6281258\n",
      "===============> 1\n",
      "gen loss 2.354297\n",
      "desc loss 0.5541643\n",
      "===============> 1\n",
      "gen loss 2.2637815\n",
      "desc loss 0.52821505\n",
      "===============> 1\n",
      "gen loss 2.543255\n",
      "desc loss 0.45012447\n",
      "===============> 1\n",
      "gen loss 2.6287599\n",
      "desc loss 0.38980448\n",
      "===============> 1\n",
      "gen loss 2.6616004\n",
      "desc loss 0.30206174\n",
      "===============> 1\n",
      "gen loss 3.107509\n",
      "desc loss 0.20344493\n",
      "===============> 1\n",
      "gen loss 3.6045094\n",
      "desc loss 0.19962335\n",
      "===============> 1\n",
      "gen loss 3.543398\n",
      "desc loss 0.16621971\n",
      "===============> 1\n",
      "gen loss 3.6240683\n",
      "desc loss 0.117539\n",
      "===============> 1\n",
      "gen loss 3.6556146\n",
      "desc loss 0.14587139\n",
      "===============> 1\n",
      "gen loss 4.040131\n",
      "desc loss 0.16530333\n",
      "===============> 1\n",
      "gen loss 4.5609326\n",
      "desc loss 0.13824232\n",
      "===============> 1\n",
      "gen loss 4.186814\n",
      "desc loss 0.1272966\n",
      "===============> 1\n",
      "gen loss 3.7914329\n",
      "desc loss 0.17325151\n",
      "===============> 1\n",
      "gen loss 4.834209\n",
      "desc loss 0.15767512\n",
      "===============> 1\n",
      "gen loss 4.1140094\n",
      "desc loss 0.16830063\n",
      "===============> 1\n",
      "gen loss 4.105731\n",
      "desc loss 0.12606019\n",
      "===============> 1\n",
      "gen loss 4.4126606\n",
      "desc loss 0.19101734\n",
      "===============> 1\n",
      "gen loss 3.8113425\n",
      "desc loss 0.16972506\n",
      "===============> 1\n",
      "gen loss 4.35576\n",
      "desc loss 0.22349209\n",
      "===============> 1\n",
      "gen loss 4.186545\n",
      "desc loss 0.18422852\n",
      "===============> 1\n",
      "gen loss 4.1730614\n",
      "desc loss 0.26278153\n",
      "===============> 1\n",
      "gen loss 4.0785594\n",
      "desc loss 0.20356409\n",
      "===============> 1\n",
      "gen loss 4.2295704\n",
      "desc loss 0.21977392\n",
      "===============> 1\n",
      "gen loss 4.803604\n",
      "desc loss 0.29886484\n",
      "===============> 1\n",
      "gen loss 3.7374048\n",
      "desc loss 0.38325214\n",
      "===============> 1\n",
      "gen loss 3.978577\n",
      "desc loss 0.35983643\n",
      "===============> 1\n",
      "gen loss 4.573831\n",
      "desc loss 0.5793483\n",
      "===============> 1\n",
      "gen loss 1.867382\n",
      "desc loss 0.7829021\n",
      "===============> 1\n",
      "gen loss 4.8614626\n",
      "desc loss 0.76555747\n",
      "===============> 1\n",
      "gen loss 3.7312481\n",
      "desc loss 0.6917009\n",
      "===============> 1\n",
      "gen loss 2.1944633\n",
      "desc loss 0.70987606\n",
      "===============> 1\n",
      "gen loss 2.9503524\n",
      "desc loss 0.6736886\n",
      "===============> 1\n",
      "gen loss 4.168631\n",
      "desc loss 0.6978399\n",
      "===============> 1\n",
      "gen loss 2.6873815\n",
      "desc loss 0.68637055\n",
      "===============> 1\n",
      "gen loss 2.1362553\n",
      "desc loss 0.6060995\n",
      "===============> 1\n",
      "gen loss 2.5022585\n",
      "desc loss 0.5736458\n",
      "===============> 1\n",
      "gen loss 3.2312782\n",
      "desc loss 0.43208483\n",
      "===============> 1\n",
      "gen loss 3.217723\n",
      "desc loss 0.32413852\n",
      "===============> 1\n",
      "gen loss 2.3775663\n",
      "desc loss 0.42122746\n",
      "===============> 1\n",
      "gen loss 2.4839506\n",
      "desc loss 0.36491758\n",
      "===============> 1\n",
      "gen loss 3.0997045\n",
      "desc loss 0.30214563\n",
      "===============> 1\n",
      "gen loss 3.4499567\n",
      "desc loss 0.36635688\n",
      "===============> 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen loss 3.1309204\n",
      "desc loss 0.38304263\n",
      "===============> 1\n",
      "gen loss 2.879986\n",
      "desc loss 0.36215734\n",
      "===============> 1\n",
      "gen loss 2.675708\n",
      "desc loss 0.3773828\n",
      "===============> 1\n",
      "gen loss 3.4862096\n",
      "desc loss 0.42047974\n",
      "===============> 1\n",
      "gen loss 3.0800607\n",
      "desc loss 0.62495124\n",
      "===============> 1\n",
      "gen loss 2.2132812\n",
      "desc loss 0.6058886\n",
      "===============> 1\n",
      "gen loss 3.3611512\n",
      "desc loss 0.6894104\n",
      "===============> 1\n",
      "gen loss 3.0662735\n",
      "desc loss 0.5465355\n",
      "===============> 1\n",
      "gen loss 3.197566\n",
      "desc loss 0.543141\n",
      "===============> 1\n",
      "gen loss 3.9905756\n",
      "desc loss 0.28301674\n",
      "===============> 1\n",
      "gen loss 4.426532\n",
      "desc loss 0.26777786\n",
      "===============> 1\n",
      "gen loss 3.506695\n",
      "desc loss 0.23316474\n",
      "===============> 1\n",
      "gen loss 5.2770786\n",
      "desc loss 0.19361223\n",
      "===============> 1\n",
      "gen loss 5.190704\n",
      "desc loss 0.21513724\n",
      "===============> 1\n",
      "gen loss 4.4485917\n",
      "desc loss 0.23877001\n",
      "===============> 1\n",
      "gen loss 3.6057425\n",
      "desc loss 0.2601883\n",
      "===============> 1\n",
      "gen loss 4.2101293\n",
      "desc loss 0.16322392\n",
      "===============> 1\n",
      "gen loss 5.108882\n",
      "desc loss 0.1957128\n",
      "===============> 1\n",
      "gen loss 4.150624\n",
      "desc loss 0.23275822\n",
      "===============> 1\n",
      "gen loss 3.5970948\n",
      "desc loss 0.23535281\n",
      "===============> 1\n",
      "gen loss 3.4541223\n",
      "desc loss 0.21090277\n",
      "===============> 1\n",
      "gen loss 5.382038\n",
      "desc loss 0.22950259\n",
      "===============> 1\n",
      "gen loss 5.34467\n",
      "desc loss 0.1674238\n",
      "===============> 1\n",
      "gen loss 3.6258962\n",
      "desc loss 0.11095305\n",
      "===============> 1\n",
      "gen loss 4.4084945\n",
      "desc loss 0.13483524\n",
      "===============> 1\n",
      "gen loss 5.523627\n",
      "desc loss 0.05118781\n",
      "===============> 1\n",
      "gen loss 6.835198\n",
      "desc loss 0.10681632\n",
      "===============> 1\n",
      "gen loss 6.716995\n",
      "desc loss 0.07889796\n",
      "===============> 1\n",
      "gen loss 5.843024\n",
      "desc loss 0.067637384\n",
      "===============> 1\n",
      "gen loss 4.2755136\n",
      "desc loss 0.10528674\n",
      "===============> 1\n",
      "gen loss 5.4115753\n",
      "desc loss 0.10951814\n",
      "===============> 1\n",
      "gen loss 7.3598695\n",
      "desc loss 0.05323734\n",
      "===============> 1\n",
      "gen loss 8.243705\n",
      "desc loss 0.15095596\n",
      "===============> 1\n",
      "gen loss 7.3314056\n",
      "desc loss 0.08864302\n",
      "===============> 1\n",
      "gen loss 6.143975\n",
      "desc loss 0.14811744\n",
      "===============> 1\n",
      "gen loss 5.348304\n",
      "desc loss 0.19740885\n",
      "===============> 1\n",
      "gen loss 6.1096554\n",
      "desc loss 0.21664353\n",
      "===============> 1\n",
      "gen loss 7.30302\n",
      "desc loss 0.31686467\n",
      "===============> 1\n",
      "gen loss 5.9300513\n",
      "desc loss 0.35837036\n",
      "===============> 1\n",
      "gen loss 3.5916047\n",
      "desc loss 0.47608683\n",
      "===============> 1\n",
      "gen loss 4.2895336\n",
      "desc loss 0.29004523\n",
      "===============> 1\n",
      "gen loss 5.597942\n",
      "desc loss 0.4654114\n",
      "===============> 1\n",
      "gen loss 5.0314746\n",
      "desc loss 0.2990691\n",
      "===============> 1\n",
      "gen loss 3.5790882\n",
      "desc loss 0.33606553\n",
      "===============> 1\n",
      "gen loss 4.3043647\n",
      "desc loss 0.21905218\n",
      "===============> 1\n",
      "gen loss 4.9305983\n",
      "desc loss 0.23504306\n",
      "===============> 1\n",
      "gen loss 5.0189056\n",
      "desc loss 0.15543428\n",
      "===============> 1\n",
      "gen loss 4.4104943\n",
      "desc loss 0.22168168\n",
      "===============> 1\n",
      "gen loss 3.9296732\n",
      "desc loss 0.16587795\n",
      "===============> 1\n",
      "gen loss 4.650358\n",
      "desc loss 0.13855663\n",
      "===============> 1\n",
      "gen loss 5.3157916\n",
      "desc loss 0.21730375\n",
      "===============> 1\n",
      "gen loss 5.3806715\n",
      "desc loss 0.117867425\n",
      "===============> 1\n",
      "gen loss 5.335173\n",
      "desc loss 0.112495005\n",
      "===============> 1\n",
      "gen loss 5.143955\n",
      "desc loss 0.092196316\n",
      "===============> 1\n",
      "gen loss 6.6031094\n",
      "desc loss 0.073776156\n",
      "===============> 1\n",
      "gen loss 7.090544\n",
      "desc loss 0.047780667\n",
      "===============> 1\n",
      "gen loss 6.5493956\n",
      "desc loss 0.060354777\n",
      "===============> 1\n",
      "gen loss 5.559897\n",
      "desc loss 0.08373748\n",
      "===============> 1\n",
      "gen loss 4.628394\n",
      "desc loss 0.10468876\n",
      "===============> 1\n",
      "gen loss 5.6640153\n",
      "desc loss 0.12023986\n",
      "===============> 1\n",
      "gen loss 6.3231816\n",
      "desc loss 0.1672256\n",
      "===============> 1\n",
      "gen loss 4.540013\n",
      "desc loss 0.12976405\n",
      "===============> 1\n",
      "gen loss 4.0406804\n",
      "desc loss 0.19540837\n",
      "===============> 1\n",
      "gen loss 6.8996534\n",
      "desc loss 0.18487057\n",
      "===============> 1\n",
      "gen loss 6.947424\n",
      "desc loss 0.19076246\n",
      "===============> 1\n",
      "gen loss 5.507124\n",
      "desc loss 0.11555402\n",
      "===============> 1\n",
      "gen loss 3.7858686\n",
      "desc loss 0.26501402\n",
      "===============> 1\n",
      "gen loss 5.1432424\n",
      "desc loss 0.16492683\n",
      "===============> 1\n",
      "gen loss 6.2296658\n",
      "desc loss 0.25738153\n",
      "===============> 1\n",
      "gen loss 5.196246\n",
      "desc loss 0.24136218\n",
      "===============> 1\n",
      "gen loss 4.6207623\n",
      "desc loss 0.199469\n",
      "===============> 1\n",
      "gen loss 4.7015934\n",
      "desc loss 0.16444717\n",
      "===============> 1\n",
      "gen loss 5.2846007\n",
      "desc loss 0.18054894\n",
      "===============> 1\n",
      "gen loss 4.7244897\n",
      "desc loss 0.26119652\n",
      "===============> 1\n",
      "gen loss 3.3411908\n",
      "desc loss 0.37773675\n",
      "===============> 1\n",
      "gen loss 4.717663\n",
      "desc loss 0.36306822\n",
      "===============> 1\n",
      "gen loss 4.4899197\n",
      "desc loss 0.23914196\n",
      "===============> 1\n",
      "gen loss 3.2548718\n",
      "desc loss 0.38135314\n",
      "===============> 1\n",
      "gen loss 2.7314887\n",
      "desc loss 0.34038126\n",
      "===============> 1\n",
      "gen loss 4.927684\n",
      "desc loss 0.4859514\n",
      "===============> 1\n",
      "gen loss 3.347206\n",
      "desc loss 0.3926462\n",
      "===============> 1\n",
      "gen loss 2.557279\n",
      "desc loss 0.45119965\n",
      "===============> 1\n",
      "gen loss 4.5115285\n",
      "desc loss 0.40689307\n",
      "===============> 1\n",
      "gen loss 4.7592435\n",
      "desc loss 0.31201327\n",
      "===============> 1\n",
      "gen loss 3.5839074\n",
      "desc loss 0.34757566\n",
      "===============> 1\n",
      "gen loss 3.1726465\n",
      "desc loss 0.32203847\n",
      "===============> 1\n",
      "gen loss 3.66\n",
      "desc loss 0.184854\n",
      "===============> 1\n",
      "gen loss 4.7424583\n",
      "desc loss 0.21706304\n",
      "===============> 1\n",
      "gen loss 4.783109\n",
      "desc loss 0.2824252\n",
      "===============> 1\n",
      "gen loss 3.6871417\n",
      "desc loss 0.16936801\n",
      "===============> 1\n",
      "gen loss 3.381587\n",
      "desc loss 0.23939453\n",
      "===============> 1\n",
      "gen loss 3.466906\n",
      "desc loss 0.19996518\n",
      "===============> 1\n",
      "gen loss 4.517321\n",
      "desc loss 0.1723876\n",
      "===============> 1\n",
      "gen loss 4.8584595\n",
      "desc loss 0.20515738\n",
      "===============> 1\n",
      "gen loss 3.97401\n",
      "desc loss 0.21571013\n",
      "===============> 1\n",
      "gen loss 3.4414709\n",
      "desc loss 0.22506961\n",
      "===============> 1\n",
      "gen loss 3.870855\n",
      "desc loss 0.18544264\n",
      "===============> 1\n",
      "gen loss 5.4165955\n",
      "desc loss 0.18949288\n",
      "===============> 1\n",
      "gen loss 5.5580044\n",
      "desc loss 0.36245176\n",
      "===============> 1\n",
      "gen loss 3.9659252\n",
      "desc loss 0.19424261\n",
      "===============> 1\n",
      "gen loss 2.8916345\n",
      "desc loss 0.35774902\n",
      "===============> 1\n",
      "gen loss 4.4584966\n",
      "desc loss 0.21484512\n",
      "===============> 1\n",
      "gen loss 5.2805824\n",
      "desc loss 0.4762714\n",
      "===============> 1\n",
      "gen loss 4.22719\n",
      "desc loss 0.18546759\n",
      "===============> 1\n",
      "gen loss 2.5481925\n",
      "desc loss 0.41551077\n",
      "===============> 1\n",
      "gen loss 3.646566\n",
      "desc loss 0.2218923\n",
      "===============> 1\n",
      "gen loss 5.237588\n",
      "desc loss 0.4265172\n",
      "===============> 1\n",
      "gen loss 4.528017\n",
      "desc loss 0.23703337\n",
      "===============> 1\n",
      "gen loss 3.267649\n",
      "desc loss 0.2263599\n",
      "===============> 1\n",
      "gen loss 2.609201\n",
      "desc loss 0.3466039\n",
      "===============> 1\n",
      "gen loss 4.391409\n",
      "desc loss 0.29747373\n",
      "===============> 1\n",
      "gen loss 4.8426595\n",
      "desc loss 0.31240207\n",
      "===============> 1\n",
      "gen loss 3.9462647\n",
      "desc loss 0.20688806\n",
      "===============> 1\n",
      "gen loss 2.6164494\n",
      "desc loss 0.41234097\n",
      "===============> 1\n",
      "gen loss 3.6575837\n",
      "desc loss 0.24555665\n",
      "===============> 1\n",
      "gen loss 5.206881\n",
      "desc loss 0.2909698\n",
      "===============> 1\n",
      "gen loss 4.7681975\n",
      "desc loss 0.40779793\n",
      "===============> 1\n",
      "gen loss 3.3089635\n",
      "desc loss 0.24375534\n",
      "===============> 1\n",
      "gen loss 2.3972979\n",
      "desc loss 0.49379602\n",
      "===============> 1\n",
      "gen loss 3.6485937\n",
      "desc loss 0.35443616\n",
      "===============> 1\n",
      "gen loss 4.600086\n",
      "desc loss 0.58787316\n",
      "===============> 1\n",
      "gen loss 3.3586168\n",
      "desc loss 0.39985433\n",
      "===============> 1\n",
      "gen loss 1.9102461\n",
      "desc loss 0.7271851\n",
      "===============> 1\n",
      "gen loss 3.1243746\n",
      "desc loss 0.46716398\n",
      "===============> 1\n",
      "gen loss 3.809245\n",
      "desc loss 0.6433803\n",
      "===============> 1\n",
      "gen loss 2.7081068\n",
      "desc loss 0.51968014\n",
      "===============> 1\n",
      "gen loss 1.7573584\n",
      "desc loss 0.7176048\n",
      "===============> 1\n",
      "gen loss 2.7123446\n",
      "desc loss 0.47595972\n",
      "===============> 1\n",
      "gen loss 3.218524\n",
      "desc loss 0.603022\n",
      "===============> 1\n",
      "gen loss 2.7063143\n",
      "desc loss 0.38843238\n",
      "===============> 1\n",
      "gen loss 2.1298761\n",
      "desc loss 0.53541005\n",
      "===============> 1\n",
      "gen loss 3.1487615\n",
      "desc loss 0.4212765\n",
      "===============> 1\n",
      "gen loss 3.5478516\n",
      "desc loss 0.3217716\n",
      "===============> 1\n",
      "gen loss 3.196566\n",
      "desc loss 0.41073668\n",
      "===============> 1\n",
      "gen loss 2.8495297\n",
      "desc loss 0.366342\n",
      "===============> 1\n",
      "gen loss 3.2589843\n",
      "desc loss 0.3431826\n",
      "===============> 1\n",
      "gen loss 4.043121\n",
      "desc loss 0.29021323\n",
      "===============> 1\n",
      "gen loss 4.1220717\n",
      "desc loss 0.2540801\n",
      "===============> 1\n",
      "gen loss 4.0030613\n",
      "desc loss 0.29909647\n",
      "===============> 1\n",
      "gen loss 3.522973\n",
      "desc loss 0.20226575\n",
      "===============> 1\n",
      "gen loss 3.59\n",
      "desc loss 0.2309834\n",
      "===============> 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen loss 3.925005\n",
      "desc loss 0.22739404\n",
      "===============> 1\n",
      "gen loss 5.129035\n",
      "desc loss 0.12784086\n",
      "===============> 1\n",
      "gen loss 5.397869\n",
      "desc loss 0.22021267\n",
      "===============> 1\n",
      "gen loss 4.9994774\n",
      "desc loss 0.14339858\n",
      "===============> 1\n",
      "gen loss 4.552226\n",
      "desc loss 0.14044121\n",
      "===============> 1\n",
      "gen loss 4.6084447\n",
      "desc loss 0.12389408\n",
      "===============> 1\n",
      "gen loss 4.8170447\n",
      "desc loss 0.14855577\n",
      "===============> 1\n",
      "gen loss 5.7850676\n",
      "desc loss 0.14730251\n",
      "===============> 1\n",
      "gen loss 5.3838897\n",
      "desc loss 0.22811751\n",
      "===============> 1\n",
      "gen loss 4.540336\n",
      "desc loss 0.19693613\n",
      "===============> 1\n",
      "gen loss 3.944361\n",
      "desc loss 0.29266953\n",
      "===============> 1\n",
      "gen loss 3.9828832\n",
      "desc loss 0.4266978\n",
      "===============> 1\n",
      "gen loss 4.4558883\n",
      "desc loss 0.31726784\n",
      "===============> 1\n",
      "gen loss 3.8021996\n",
      "desc loss 0.4735567\n",
      "===============> 1\n",
      "gen loss 3.100579\n",
      "desc loss 0.4272036\n",
      "===============> 1\n",
      "gen loss 3.2782404\n",
      "desc loss 0.5894127\n",
      "===============> 1\n",
      "gen loss 3.2258697\n",
      "desc loss 0.3537051\n",
      "===============> 1\n",
      "gen loss 3.6870184\n",
      "desc loss 0.31387138\n",
      "===============> 1\n",
      "gen loss 4.1209345\n",
      "desc loss 0.29514\n",
      "===============> 1\n",
      "gen loss 3.2072735\n",
      "desc loss 0.2363193\n",
      "===============> 1\n",
      "gen loss 3.5652986\n",
      "desc loss 0.17977288\n",
      "===============> 1\n",
      "gen loss 4.5250406\n",
      "desc loss 0.18855634\n",
      "===============> 1\n",
      "gen loss 5.0625005\n",
      "desc loss 0.24163921\n",
      "===============> 1\n",
      "gen loss 4.1443696\n",
      "desc loss 0.23510891\n",
      "===============> 1\n",
      "gen loss 2.9245605\n",
      "desc loss 0.3555291\n",
      "===============> 1\n",
      "gen loss 4.2553716\n",
      "desc loss 0.2470651\n",
      "===============> 1\n",
      "gen loss 5.213497\n",
      "desc loss 0.55997735\n",
      "===============> 1\n",
      "gen loss 2.7442696\n",
      "desc loss 0.4271291\n",
      "===============> 1\n",
      "gen loss 2.7491338\n",
      "desc loss 0.39750493\n",
      "===============> 1\n",
      "gen loss 3.4783094\n",
      "desc loss 0.44760153\n",
      "===============> 1\n",
      "gen loss 4.217378\n",
      "desc loss 0.4957404\n",
      "===============> 1\n",
      "gen loss 2.9363368\n",
      "desc loss 0.34868786\n",
      "===============> 1\n",
      "gen loss 2.678206\n",
      "desc loss 0.4274903\n",
      "===============> 1\n",
      "gen loss 3.0246117\n",
      "desc loss 0.4734375\n",
      "===============> 1\n",
      "gen loss 3.9455595\n",
      "desc loss 0.3535873\n",
      "===============> 1\n",
      "gen loss 4.161792\n",
      "desc loss 0.44593143\n",
      "===============> 1\n",
      "gen loss 3.455734\n",
      "desc loss 0.4047066\n",
      "===============> 2\n",
      "gen loss 2.6279678\n",
      "desc loss 0.56416845\n",
      "===============> 2\n",
      "gen loss 3.2707396\n",
      "desc loss 0.37227166\n",
      "===============> 2\n",
      "gen loss 4.030433\n",
      "desc loss 0.4396003\n",
      "===============> 2\n",
      "gen loss 3.4621234\n",
      "desc loss 0.35247058\n",
      "===============> 2\n",
      "gen loss 3.6682627\n",
      "desc loss 0.333351\n",
      "===============> 2\n",
      "gen loss 3.12775\n",
      "desc loss 0.34179556\n",
      "===============> 2\n",
      "gen loss 3.6384497\n",
      "desc loss 0.34963635\n",
      "===============> 2\n",
      "gen loss 3.9443946\n",
      "desc loss 0.40765727\n",
      "===============> 2\n",
      "gen loss 4.000712\n",
      "desc loss 0.41571492\n",
      "===============> 2\n",
      "gen loss 3.6271055\n",
      "desc loss 0.33185047\n",
      "===============> 2\n",
      "gen loss 2.9622018\n",
      "desc loss 0.52163684\n",
      "===============> 2\n",
      "gen loss 3.9179735\n",
      "desc loss 0.29591542\n",
      "===============> 2\n",
      "gen loss 4.1827607\n",
      "desc loss 0.4335193\n",
      "===============> 2\n",
      "gen loss 3.857669\n",
      "desc loss 0.46558058\n",
      "===============> 2\n",
      "gen loss 2.9514008\n",
      "desc loss 0.49227363\n",
      "===============> 2\n",
      "gen loss 2.8435962\n",
      "desc loss 0.50837404\n",
      "===============> 2\n",
      "gen loss 3.2452462\n",
      "desc loss 0.5317246\n",
      "===============> 2\n",
      "gen loss 3.129634\n",
      "desc loss 0.5196835\n",
      "===============> 2\n",
      "gen loss 3.3551447\n",
      "desc loss 0.46038285\n",
      "===============> 2\n",
      "gen loss 3.067057\n",
      "desc loss 0.41831672\n",
      "===============> 2\n",
      "gen loss 2.516088\n",
      "desc loss 0.55009085\n",
      "===============> 2\n",
      "gen loss 2.9886417\n",
      "desc loss 0.48277625\n",
      "===============> 2\n",
      "gen loss 3.57628\n",
      "desc loss 0.4976718\n",
      "===============> 2\n",
      "gen loss 2.8831732\n",
      "desc loss 0.37502882\n",
      "===============> 2\n",
      "gen loss 2.889023\n",
      "desc loss 0.38006824\n",
      "===============> 2\n",
      "gen loss 3.1331666\n",
      "desc loss 0.37968224\n",
      "===============> 2\n",
      "gen loss 3.5514321\n",
      "desc loss 0.2746582\n",
      "===============> 2\n",
      "gen loss 3.3043036\n",
      "desc loss 0.22518396\n",
      "===============> 2\n",
      "gen loss 3.3723638\n",
      "desc loss 0.19460356\n",
      "===============> 2\n",
      "gen loss 3.8821392\n",
      "desc loss 0.3024326\n",
      "===============> 2\n",
      "gen loss 3.7735167\n",
      "desc loss 0.2717767\n",
      "===============> 2\n",
      "gen loss 3.5440016\n",
      "desc loss 0.20638707\n",
      "===============> 2\n",
      "gen loss 3.550685\n",
      "desc loss 0.2380346\n",
      "===============> 2\n",
      "gen loss 3.8467014\n",
      "desc loss 0.19903901\n",
      "===============> 2\n",
      "gen loss 3.887696\n",
      "desc loss 0.20706469\n",
      "===============> 2\n",
      "gen loss 3.9520032\n",
      "desc loss 0.3227387\n",
      "===============> 2\n",
      "gen loss 4.004176\n",
      "desc loss 0.2385568\n",
      "===============> 2\n",
      "gen loss 3.47188\n",
      "desc loss 0.30845535\n",
      "===============> 2\n",
      "gen loss 3.558656\n",
      "desc loss 0.34817523\n",
      "===============> 2\n",
      "gen loss 3.6781805\n",
      "desc loss 0.34785223\n",
      "===============> 2\n",
      "gen loss 3.941226\n",
      "desc loss 0.28395623\n",
      "===============> 2\n",
      "gen loss 3.7305267\n",
      "desc loss 0.28585565\n",
      "===============> 2\n",
      "gen loss 3.6293573\n",
      "desc loss 0.36912233\n",
      "===============> 2\n",
      "gen loss 3.15972\n",
      "desc loss 0.30142915\n",
      "===============> 2\n",
      "gen loss 3.6375017\n",
      "desc loss 0.37557754\n",
      "===============> 2\n",
      "gen loss 3.5825815\n",
      "desc loss 0.34460592\n",
      "===============> 2\n",
      "gen loss 3.4461012\n",
      "desc loss 0.3225702\n",
      "===============> 2\n",
      "gen loss 3.252739\n",
      "desc loss 0.34351096\n",
      "===============> 2\n",
      "gen loss 3.838067\n",
      "desc loss 0.28642908\n",
      "===============> 2\n",
      "gen loss 3.8952386\n",
      "desc loss 0.38742608\n",
      "===============> 2\n",
      "gen loss 3.2074163\n",
      "desc loss 0.35281742\n",
      "===============> 2\n",
      "gen loss 3.460279\n",
      "desc loss 0.27518383\n",
      "===============> 2\n",
      "gen loss 4.1287236\n",
      "desc loss 0.23745808\n",
      "===============> 2\n",
      "gen loss 4.097143\n",
      "desc loss 0.22820151\n",
      "===============> 2\n",
      "gen loss 3.4255438\n",
      "desc loss 0.25604135\n",
      "===============> 2\n",
      "gen loss 3.7187128\n",
      "desc loss 0.27232334\n",
      "===============> 2\n",
      "gen loss 4.0785265\n",
      "desc loss 0.32341397\n",
      "===============> 2\n",
      "gen loss 4.142336\n",
      "desc loss 0.23213317\n",
      "===============> 2\n",
      "gen loss 4.141286\n",
      "desc loss 0.33496037\n",
      "===============> 2\n",
      "gen loss 4.1936893\n",
      "desc loss 0.46760798\n",
      "===============> 2\n",
      "gen loss 3.894846\n",
      "desc loss 0.29215276\n",
      "===============> 2\n",
      "gen loss 3.2608569\n",
      "desc loss 0.38923365\n",
      "===============> 2\n",
      "gen loss 4.52866\n",
      "desc loss 0.3324836\n",
      "===============> 2\n",
      "gen loss 3.8788629\n",
      "desc loss 0.37817204\n",
      "===============> 2\n",
      "gen loss 2.5332444\n",
      "desc loss 0.5821099\n",
      "===============> 2\n",
      "gen loss 4.7047725\n",
      "desc loss 0.34428817\n",
      "===============> 2\n",
      "gen loss 4.6067157\n",
      "desc loss 0.48029268\n",
      "===============> 2\n",
      "gen loss 2.3552551\n",
      "desc loss 0.5368621\n",
      "===============> 2\n",
      "gen loss 3.3499117\n",
      "desc loss 0.41529557\n",
      "===============> 2\n",
      "gen loss 4.8341436\n",
      "desc loss 0.5434548\n",
      "===============> 2\n",
      "gen loss 4.275052\n",
      "desc loss 0.38638523\n",
      "===============> 2\n",
      "gen loss 2.263808\n",
      "desc loss 0.5618948\n",
      "===============> 2\n",
      "gen loss 2.9220362\n",
      "desc loss 0.2772001\n",
      "===============> 2\n",
      "gen loss 4.779186\n",
      "desc loss 0.4563077\n",
      "===============> 2\n",
      "gen loss 4.250909\n",
      "desc loss 0.40720585\n",
      "===============> 2\n",
      "gen loss 2.5240514\n",
      "desc loss 0.48413157\n",
      "===============> 2\n",
      "gen loss 3.3314385\n",
      "desc loss 0.30326205\n",
      "===============> 2\n",
      "gen loss 4.504372\n",
      "desc loss 0.3341033\n",
      "===============> 2\n",
      "gen loss 4.5933948\n",
      "desc loss 0.29449877\n",
      "===============> 2\n",
      "gen loss 3.5626483\n",
      "desc loss 0.28906626\n",
      "===============> 2\n",
      "gen loss 2.580852\n",
      "desc loss 0.4348613\n",
      "===============> 2\n",
      "gen loss 3.9007533\n",
      "desc loss 0.32120192\n",
      "===============> 2\n",
      "gen loss 4.687324\n",
      "desc loss 0.3718358\n",
      "===============> 2\n",
      "gen loss 4.5615516\n",
      "desc loss 0.34546685\n",
      "===============> 2\n",
      "gen loss 3.3055334\n",
      "desc loss 0.4161143\n",
      "===============> 2\n",
      "gen loss 2.9358315\n",
      "desc loss 0.5070085\n",
      "===============> 2\n",
      "gen loss 4.633248\n",
      "desc loss 0.4947309\n",
      "===============> 2\n",
      "gen loss 4.1483316\n",
      "desc loss 0.555085\n",
      "===============> 2\n",
      "gen loss 2.6103828\n",
      "desc loss 0.68644387\n",
      "===============> 2\n",
      "gen loss 3.5298648\n",
      "desc loss 0.50564146\n",
      "===============> 2\n",
      "gen loss 4.6838183\n",
      "desc loss 0.92203814\n",
      "===============> 2\n",
      "gen loss 3.195962\n",
      "desc loss 0.57122576\n",
      "===============> 2\n",
      "gen loss 2.2833014\n",
      "desc loss 0.78897774\n",
      "===============> 2\n",
      "gen loss 3.4250665\n",
      "desc loss 0.6835185\n",
      "===============> 2\n",
      "gen loss 4.478386\n",
      "desc loss 0.8109964\n",
      "===============> 2\n",
      "gen loss 2.8729692\n",
      "desc loss 0.54870856\n",
      "===============> 2\n",
      "gen loss 1.8292289\n",
      "desc loss 0.86897564\n",
      "===============> 2\n",
      "gen loss 2.857702\n",
      "desc loss 0.47087204\n",
      "===============> 2\n",
      "gen loss 4.6132627\n",
      "desc loss 0.7075399\n",
      "===============> 2\n",
      "gen loss 3.7360888\n",
      "desc loss 0.5809158\n",
      "===============> 2\n",
      "gen loss 1.6456101\n",
      "desc loss 0.70510006\n",
      "===============> 2\n",
      "gen loss 2.0011375\n",
      "desc loss 0.5691593\n",
      "===============> 2\n",
      "gen loss 3.740486\n",
      "desc loss 0.45416355\n",
      "===============> 2\n",
      "gen loss 4.1492977\n",
      "desc loss 0.565889\n",
      "===============> 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen loss 3.1016955\n",
      "desc loss 0.52157164\n",
      "===============> 2\n",
      "gen loss 1.404516\n",
      "desc loss 0.7507964\n",
      "===============> 2\n",
      "gen loss 2.5500267\n",
      "desc loss 0.43928787\n",
      "===============> 2\n",
      "gen loss 3.512574\n",
      "desc loss 0.49076447\n",
      "===============> 2\n",
      "gen loss 3.546702\n",
      "desc loss 0.47316447\n",
      "===============> 2\n",
      "gen loss 2.3376582\n",
      "desc loss 0.5221602\n",
      "===============> 2\n",
      "gen loss 1.7770686\n",
      "desc loss 0.6367169\n",
      "===============> 2\n",
      "gen loss 2.9494038\n",
      "desc loss 0.47250497\n",
      "===============> 2\n",
      "gen loss 3.7059815\n",
      "desc loss 0.607987\n",
      "===============> 2\n",
      "gen loss 2.5542216\n",
      "desc loss 0.58401394\n",
      "===============> 2\n",
      "gen loss 1.6829019\n",
      "desc loss 0.5756834\n",
      "===============> 2\n",
      "gen loss 1.8567078\n",
      "desc loss 0.66011864\n",
      "===============> 2\n",
      "gen loss 3.2220037\n",
      "desc loss 0.5873945\n",
      "===============> 2\n",
      "gen loss 3.1072826\n",
      "desc loss 0.58285177\n",
      "===============> 2\n",
      "gen loss 2.2478957\n",
      "desc loss 0.53060424\n",
      "===============> 2\n",
      "gen loss 1.8613193\n",
      "desc loss 0.5077653\n",
      "===============> 2\n",
      "gen loss 2.227218\n",
      "desc loss 0.44976822\n",
      "===============> 2\n",
      "gen loss 2.8768659\n",
      "desc loss 0.48108047\n",
      "===============> 2\n",
      "gen loss 3.2892504\n",
      "desc loss 0.5365056\n",
      "===============> 2\n",
      "gen loss 2.9723215\n",
      "desc loss 0.4071008\n",
      "===============> 2\n",
      "gen loss 2.2224586\n",
      "desc loss 0.517985\n",
      "===============> 2\n",
      "gen loss 2.2859197\n",
      "desc loss 0.4525389\n",
      "===============> 2\n",
      "gen loss 2.9445453\n",
      "desc loss 0.45563763\n",
      "===============> 2\n",
      "gen loss 3.46479\n",
      "desc loss 0.46123958\n",
      "===============> 2\n",
      "gen loss 3.2467194\n",
      "desc loss 0.49410975\n",
      "===============> 2\n",
      "gen loss 2.1621118\n",
      "desc loss 0.53075635\n",
      "===============> 2\n",
      "gen loss 2.1739085\n",
      "desc loss 0.49343613\n",
      "===============> 2\n",
      "gen loss 2.5446317\n",
      "desc loss 0.3837785\n",
      "===============> 2\n",
      "gen loss 3.4561236\n",
      "desc loss 0.4631622\n",
      "===============> 2\n",
      "gen loss 3.2738311\n",
      "desc loss 0.43996352\n",
      "===============> 2\n",
      "gen loss 2.925937\n",
      "desc loss 0.384214\n",
      "===============> 2\n",
      "gen loss 2.575038\n",
      "desc loss 0.3898893\n",
      "===============> 2\n",
      "gen loss 2.4426289\n",
      "desc loss 0.3695385\n",
      "===============> 2\n",
      "gen loss 2.6503644\n",
      "desc loss 0.3902889\n",
      "===============> 2\n",
      "gen loss 3.1371856\n",
      "desc loss 0.3396482\n",
      "===============> 2\n",
      "gen loss 3.477989\n",
      "desc loss 0.3689705\n",
      "===============> 2\n",
      "gen loss 3.1531608\n",
      "desc loss 0.33039942\n",
      "===============> 2\n",
      "gen loss 2.5066085\n",
      "desc loss 0.41029155\n",
      "===============> 2\n",
      "gen loss 2.6029236\n",
      "desc loss 0.43283117\n",
      "===============> 2\n",
      "gen loss 2.6601954\n",
      "desc loss 0.38143682\n",
      "===============> 2\n",
      "gen loss 2.932528\n",
      "desc loss 0.46950886\n",
      "===============> 2\n",
      "gen loss 2.9470816\n",
      "desc loss 0.36598176\n",
      "===============> 2\n",
      "gen loss 2.8217034\n",
      "desc loss 0.40455657\n",
      "===============> 2\n",
      "gen loss 2.5818157\n",
      "desc loss 0.44714063\n",
      "===============> 2\n",
      "gen loss 2.5717673\n",
      "desc loss 0.38569313\n",
      "===============> 2\n",
      "gen loss 2.6413085\n",
      "desc loss 0.4348923\n",
      "===============> 2\n",
      "gen loss 2.9858725\n",
      "desc loss 0.34145594\n",
      "===============> 2\n",
      "gen loss 3.0153043\n",
      "desc loss 0.3645534\n",
      "===============> 2\n",
      "gen loss 2.6844752\n",
      "desc loss 0.4634449\n",
      "===============> 2\n",
      "gen loss 2.3248518\n",
      "desc loss 0.449351\n",
      "===============> 2\n",
      "gen loss 2.496884\n",
      "desc loss 0.41128665\n",
      "===============> 2\n",
      "gen loss 2.3844976\n",
      "desc loss 0.45035946\n",
      "===============> 2\n",
      "gen loss 2.6761918\n",
      "desc loss 0.39410484\n",
      "===============> 2\n",
      "gen loss 2.7912645\n",
      "desc loss 0.3887828\n",
      "===============> 2\n",
      "gen loss 2.1955178\n",
      "desc loss 0.43665192\n",
      "===============> 2\n",
      "gen loss 2.489259\n",
      "desc loss 0.3795175\n",
      "===============> 2\n",
      "gen loss 2.634115\n",
      "desc loss 0.4111259\n",
      "===============> 2\n",
      "gen loss 2.8377428\n",
      "desc loss 0.33782297\n",
      "===============> 2\n",
      "gen loss 2.829104\n",
      "desc loss 0.41267914\n",
      "===============> 2\n",
      "gen loss 2.7191267\n",
      "desc loss 0.4439929\n",
      "===============> 2\n",
      "gen loss 2.5165446\n",
      "desc loss 0.49585524\n",
      "===============> 2\n",
      "gen loss 2.7903614\n",
      "desc loss 0.42883772\n",
      "===============> 2\n",
      "gen loss 2.7384646\n",
      "desc loss 0.4343624\n",
      "===============> 2\n",
      "gen loss 2.9790087\n",
      "desc loss 0.474935\n",
      "===============> 2\n",
      "gen loss 2.6721876\n",
      "desc loss 0.5709554\n",
      "===============> 2\n",
      "gen loss 2.4652605\n",
      "desc loss 0.48574343\n",
      "===============> 2\n",
      "gen loss 2.7621708\n",
      "desc loss 0.48015106\n",
      "===============> 2\n",
      "gen loss 3.7283525\n",
      "desc loss 0.4731198\n",
      "===============> 2\n",
      "gen loss 2.910004\n",
      "desc loss 0.48290077\n",
      "===============> 2\n",
      "gen loss 2.7010038\n",
      "desc loss 0.5029349\n",
      "===============> 2\n",
      "gen loss 3.1178155\n",
      "desc loss 0.39392325\n",
      "===============> 2\n",
      "gen loss 3.789687\n",
      "desc loss 0.36762652\n",
      "===============> 2\n",
      "gen loss 3.9100628\n",
      "desc loss 0.3445201\n",
      "===============> 2\n",
      "gen loss 3.312225\n",
      "desc loss 0.2781253\n",
      "===============> 2\n",
      "gen loss 2.95605\n",
      "desc loss 0.41052097\n",
      "===============> 2\n",
      "gen loss 4.113565\n",
      "desc loss 0.25805786\n",
      "===============> 2\n",
      "gen loss 4.1148467\n",
      "desc loss 0.35167137\n",
      "===============> 2\n",
      "gen loss 3.5280743\n",
      "desc loss 0.25033578\n",
      "===============> 2\n",
      "gen loss 4.37792\n",
      "desc loss 0.27325082\n",
      "===============> 2\n",
      "gen loss 4.3239155\n",
      "desc loss 0.32774633\n",
      "===============> 2\n",
      "gen loss 2.8578546\n",
      "desc loss 0.44551104\n",
      "===============> 2\n",
      "gen loss 4.1682057\n",
      "desc loss 0.31241918\n",
      "===============> 2\n",
      "gen loss 4.6693544\n",
      "desc loss 0.35969198\n",
      "===============> 2\n",
      "gen loss 2.6450982\n",
      "desc loss 0.3899329\n",
      "===============> 2\n",
      "gen loss 3.211911\n",
      "desc loss 0.4143985\n",
      "===============> 2\n",
      "gen loss 5.139403\n",
      "desc loss 0.57827514\n",
      "===============> 2\n",
      "gen loss 2.5255399\n",
      "desc loss 0.54325104\n",
      "===============> 2\n",
      "gen loss 2.3154306\n",
      "desc loss 0.52467376\n",
      "===============> 2\n",
      "gen loss 5.098069\n",
      "desc loss 0.8043419\n",
      "===============> 2\n",
      "gen loss 3.394464\n",
      "desc loss 0.588935\n",
      "===============> 2\n",
      "gen loss 1.6580757\n",
      "desc loss 0.82325816\n",
      "===============> 2\n",
      "gen loss 4.1603003\n",
      "desc loss 1.00003\n",
      "===============> 2\n",
      "gen loss 3.986471\n",
      "desc loss 0.7457405\n",
      "===============> 2\n",
      "gen loss 2.5343485\n",
      "desc loss 0.7278889\n",
      "===============> 2\n",
      "gen loss 2.112491\n",
      "desc loss 0.67022496\n",
      "===============> 2\n",
      "gen loss 3.361632\n",
      "desc loss 0.7063947\n",
      "===============> 2\n",
      "gen loss 4.2064185\n",
      "desc loss 0.7599892\n",
      "===============> 2\n",
      "gen loss 2.534939\n",
      "desc loss 0.5493493\n",
      "===============> 2\n",
      "gen loss 2.165288\n",
      "desc loss 0.6980223\n",
      "===============> 2\n",
      "gen loss 3.0231462\n",
      "desc loss 0.54520464\n",
      "===============> 2\n",
      "gen loss 3.9960394\n",
      "desc loss 0.5769359\n",
      "===============> 2\n",
      "gen loss 2.911838\n",
      "desc loss 0.6022757\n",
      "===============> 2\n",
      "gen loss 2.665166\n",
      "desc loss 0.45550683\n",
      "===============> 2\n",
      "gen loss 3.2467926\n",
      "desc loss 0.48343807\n",
      "===============> 2\n",
      "gen loss 3.387837\n",
      "desc loss 0.48493466\n",
      "===============> 2\n",
      "gen loss 3.3071477\n",
      "desc loss 0.39889136\n",
      "===============> 2\n",
      "gen loss 3.0376983\n",
      "desc loss 0.38944036\n",
      "===============> 2\n",
      "gen loss 2.9640384\n",
      "desc loss 0.45891476\n",
      "===============> 2\n",
      "gen loss 3.2733583\n",
      "desc loss 0.4530851\n",
      "===============> 2\n",
      "gen loss 3.443974\n",
      "desc loss 0.4581601\n",
      "===============> 2\n",
      "gen loss 3.5488873\n",
      "desc loss 0.6426226\n",
      "===============> 2\n",
      "gen loss 3.05544\n",
      "desc loss 0.52551687\n",
      "===============> 2\n",
      "gen loss 2.770035\n",
      "desc loss 0.5543041\n",
      "===============> 2\n",
      "gen loss 2.9672303\n",
      "desc loss 0.5990285\n",
      "===============> 2\n",
      "gen loss 3.1640823\n",
      "desc loss 0.43473884\n",
      "===============> 2\n",
      "gen loss 3.3943963\n",
      "desc loss 0.595084\n",
      "===============> 2\n",
      "gen loss 2.5210612\n",
      "desc loss 0.5617578\n",
      "===============> 2\n",
      "gen loss 2.6713777\n",
      "desc loss 0.4820925\n",
      "===============> 2\n",
      "gen loss 2.9309983\n",
      "desc loss 0.6082021\n",
      "===============> 2\n",
      "gen loss 2.9248202\n",
      "desc loss 0.4896372\n",
      "===============> 2\n",
      "gen loss 2.8135016\n",
      "desc loss 0.52275884\n",
      "===============> 2\n",
      "gen loss 2.6882982\n",
      "desc loss 0.44975498\n",
      "===============> 2\n",
      "gen loss 2.5687199\n",
      "desc loss 0.50165623\n",
      "===============> 2\n",
      "gen loss 3.163138\n",
      "desc loss 0.40681738\n",
      "===============> 2\n",
      "gen loss 3.213609\n",
      "desc loss 0.50282305\n",
      "===============> 2\n",
      "gen loss 2.427049\n",
      "desc loss 0.5501106\n",
      "===============> 2\n",
      "gen loss 2.167858\n",
      "desc loss 0.4553632\n",
      "===============> 2\n",
      "gen loss 2.9459968\n",
      "desc loss 0.42114115\n",
      "===============> 2\n",
      "gen loss 3.5456882\n",
      "desc loss 0.4585064\n",
      "===============> 2\n",
      "gen loss 2.794113\n",
      "desc loss 0.40020248\n",
      "===============> 2\n",
      "gen loss 2.4463036\n",
      "desc loss 0.42886698\n",
      "===============> 2\n",
      "gen loss 2.3576891\n",
      "desc loss 0.4399665\n",
      "===============> 2\n",
      "gen loss 3.0279565\n",
      "desc loss 0.42417368\n",
      "===============> 2\n",
      "gen loss 3.1139965\n",
      "desc loss 0.4474883\n",
      "===============> 2\n",
      "gen loss 2.661782\n",
      "desc loss 0.5340523\n",
      "===============> 2\n",
      "gen loss 2.5986183\n",
      "desc loss 0.43860483\n",
      "===============> 2\n",
      "gen loss 2.5990782\n",
      "desc loss 0.5513177\n",
      "===============> 2\n",
      "gen loss 2.7866852\n",
      "desc loss 0.42786562\n",
      "===============> 2\n",
      "gen loss 2.655392\n",
      "desc loss 0.4661143\n",
      "===============> 2\n",
      "gen loss 2.8447633\n",
      "desc loss 0.4429436\n",
      "===============> 2\n",
      "gen loss 2.6886306\n",
      "desc loss 0.5919062\n",
      "===============> 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen loss 2.9826977\n",
      "desc loss 0.5204417\n",
      "===============> 2\n",
      "gen loss 2.9481232\n",
      "desc loss 0.566997\n",
      "===============> 2\n",
      "gen loss 2.5107992\n",
      "desc loss 0.53065276\n",
      "===============> 2\n",
      "gen loss 2.6293936\n",
      "desc loss 0.5411577\n",
      "===============> 2\n",
      "gen loss 2.2417037\n",
      "desc loss 0.4687422\n",
      "===============> 2\n",
      "gen loss 2.9156253\n",
      "desc loss 0.58795005\n",
      "===============> 2\n",
      "gen loss 3.1919243\n",
      "desc loss 0.6522014\n",
      "===============> 2\n",
      "gen loss 2.5922122\n",
      "desc loss 0.5193645\n",
      "===============> 2\n",
      "gen loss 2.251963\n",
      "desc loss 0.5366272\n",
      "===============> 2\n",
      "gen loss 2.8455114\n",
      "desc loss 0.5054479\n",
      "===============> 2\n",
      "gen loss 3.0245423\n",
      "desc loss 0.49748206\n",
      "===============> 2\n",
      "gen loss 2.9323974\n",
      "desc loss 0.38046223\n",
      "===============> 2\n",
      "gen loss 2.3149624\n",
      "desc loss 0.39048362\n",
      "===============> 2\n",
      "gen loss 2.2929406\n",
      "desc loss 0.44000334\n",
      "===============> 2\n",
      "gen loss 2.515858\n",
      "desc loss 0.30420762\n",
      "===============> 2\n",
      "gen loss 3.4267263\n",
      "desc loss 0.32311133\n",
      "===============> 2\n",
      "gen loss 3.2313406\n",
      "desc loss 0.36951163\n",
      "===============> 2\n",
      "gen loss 2.6932297\n",
      "desc loss 0.34661013\n",
      "===============> 2\n",
      "gen loss 2.4701476\n",
      "desc loss 0.35504878\n",
      "===============> 2\n",
      "gen loss 2.8327088\n",
      "desc loss 0.32707673\n",
      "===============> 2\n",
      "gen loss 3.6798997\n",
      "desc loss 0.42048454\n",
      "===============> 2\n",
      "gen loss 3.25029\n",
      "desc loss 0.31827325\n",
      "===============> 2\n",
      "gen loss 2.695497\n",
      "desc loss 0.34171414\n",
      "===============> 2\n",
      "gen loss 2.6651645\n",
      "desc loss 0.38062125\n",
      "===============> 2\n",
      "gen loss 3.2077935\n",
      "desc loss 0.3539472\n",
      "===============> 2\n",
      "gen loss 3.195997\n",
      "desc loss 0.4116738\n",
      "===============> 2\n",
      "gen loss 3.2216547\n",
      "desc loss 0.42594075\n",
      "===============> 2\n",
      "gen loss 2.9630582\n",
      "desc loss 0.51145804\n",
      "===============> 2\n",
      "gen loss 2.8599262\n",
      "desc loss 0.46264082\n",
      "===============> 2\n",
      "gen loss 2.9616208\n",
      "desc loss 0.55113125\n",
      "===============> 2\n",
      "gen loss 3.280148\n",
      "desc loss 0.43615776\n",
      "===============> 2\n",
      "gen loss 2.8522706\n",
      "desc loss 0.5509418\n",
      "===============> 2\n",
      "gen loss 2.4642463\n",
      "desc loss 0.62124056\n",
      "===============> 2\n",
      "gen loss 3.5121567\n",
      "desc loss 0.65299505\n",
      "===============> 2\n",
      "gen loss 2.3080525\n",
      "desc loss 0.6585256\n",
      "===============> 2\n",
      "gen loss 2.9097235\n",
      "desc loss 0.62921524\n",
      "===============> 2\n",
      "gen loss 2.5030315\n",
      "desc loss 0.5771009\n",
      "===============> 2\n",
      "gen loss 2.6154187\n",
      "desc loss 0.85929465\n",
      "===============> 2\n",
      "gen loss 2.1281397\n",
      "desc loss 0.723197\n",
      "===============> 2\n",
      "gen loss 2.4824355\n",
      "desc loss 0.81182927\n",
      "===============> 2\n",
      "gen loss 2.8548987\n",
      "desc loss 0.62957585\n",
      "===============> 2\n",
      "gen loss 1.9601825\n",
      "desc loss 0.6641406\n",
      "===============> 2\n",
      "gen loss 2.374113\n",
      "desc loss 0.6271377\n",
      "===============> 2\n",
      "gen loss 2.545528\n",
      "desc loss 0.5845603\n",
      "===============> 2\n",
      "gen loss 2.4368627\n",
      "desc loss 0.5628586\n",
      "===============> 2\n",
      "gen loss 2.304484\n",
      "desc loss 0.5393345\n",
      "===============> 2\n",
      "gen loss 2.107016\n",
      "desc loss 0.6030482\n",
      "===============> 2\n",
      "gen loss 2.3323069\n",
      "desc loss 0.5026754\n",
      "===============> 2\n",
      "gen loss 2.5000474\n",
      "desc loss 0.5613071\n",
      "===============> 2\n",
      "gen loss 2.0490487\n",
      "desc loss 0.48786992\n",
      "===============> 2\n",
      "gen loss 2.3992248\n",
      "desc loss 0.47781485\n",
      "===============> 2\n",
      "gen loss 2.460872\n",
      "desc loss 0.5225545\n",
      "===============> 2\n",
      "gen loss 1.9470845\n",
      "desc loss 0.5943297\n",
      "===============> 2\n",
      "gen loss 2.0988505\n",
      "desc loss 0.5651521\n",
      "===============> 2\n"
     ]
    }
   ],
   "source": [
    "train(train_ip,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x15e1dd9bec8>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAQ9klEQVR4nO3db4xVZX4H8O93ZlAQRwFBHdlJ3QVjRBS2IFbZVJp1iUuIuOo2ywuDqcn4Asxu0hea7Ys1aUi06W7ti6LB+ocadbMJbjQrCSASscYYBoICpVWLU3ZkFBVEQYRh5tcXc2hncc7vGe6595wrv+8nmdyZ+5vn3ufeme89597nPOehmUFEzn4tVXdARMqhsIsEobCLBKGwiwShsIsE0VbmnZE0krl1jQyIFGdmI4asUNhJ3gLgnwG0AvhXM3so8ftoa8u/y/7+/iLdkRF4L65A+gU21T5V9wwODtbctqhGPi6g2seWp+bdeJKtAP4FwI8BzACwlOSMenVMROqryHv2eQDeN7O9ZnYCwG8BLKlPt0Sk3oqEfSqAPw77uTe77k+Q7CLZTbJb78lFqlPkPftIb2q+kWYzWw1gNQC0tLQo7SIVKbJl7wXQOezn7wDYX6w7ItIoRcK+FcAVJL9L8hwAPwPwUn26JSL1VvNuvJmdJLkCwHoMDb09aWa7E200vFayop+TpNp/Wz+HOVsfl4dlPiiSZ98zKNJk8g6q0eGyIkEo7CJBKOwiQSjsIkEo7CJBKOwiQZQ6nx0AWlryX1+acVrg2S41ldP7ewHpv1mV49XeYzsbp7CmaMsuEoTCLhKEwi4ShMIuEoTCLhKEwi4SROlDb1J/Y8aMya21t7e7ba+99lq3Pn78eLe+fft2t37o0KHc2smTJ922qeGxzs5Ot75o0aLc2pEjR9y2u3btcuvd3d1uvRlpyy4ShMIuEoTCLhKEwi4ShMIuEoTCLhKEwi4ShMbZm0BqPHny5Mlu/emnn86tzZw502176aWXuvVU37744gu37k1xnTBhgtvWW/G3qNTU26NHj7r1WbNmufW9e/eecZ8aTVt2kSAUdpEgFHaRIBR2kSAUdpEgFHaRIBR2kSA0zt4EUmPZY8eOdeve3Oy+vj637aRJk9z6Oeec49bPO+88t+5p5Dh6Suo5Tz2upUuXuvWVK1eecZ8ardCzTbIHwJcABgCcNLO59eiUiNRfPV5a/8rMPq3D7YhIA+k9u0gQRcNuADaQ3Eaya6RfINlFspvkt++kXSJnkaK78fPNbD/JiwFsJPmfZrZl+C+Y2WoAqwGAZHULf4kEV2jLbmb7s8sDAH4PYF49OiUi9Vdz2EmOJ9l+6nsACwH4598Vkcqw1iV1SX4PQ1tzYOjtwHNm5g4ukjRvbDV1HnEZmTdmfNFFF7lt33jjDbfe0dHh1vv7+916kWWTU+esTy0n7d1+qm3Kq6++6tYXL17s1o8dO1bo/j1mNuIDr/k9u5ntBeDP4BeRpqGhN5EgFHaRIBR2kSAUdpEgFHaRIEqfYzgwMFD2XZ71vOHTgwcPum0HBwfdemoa6uHDh926d5rrxx57zG174MABt57q+/z583Nrr7zyitu2tbXVrU+fPt2t33333W790UcfdeuNoC27SBAKu0gQCrtIEAq7SBAKu0gQCrtIEAq7SBA1T3Gt6c50pprSjRs3zq3v3LnTrXd2drr1zZs3u/WurhHPVgYA2Ldvn9s2pcjpoG+//Xa37Z133unWb7rpJrfe09Pj1ufMmZNbK3osSt4UV23ZRYJQ2EWCUNhFglDYRYJQ2EWCUNhFglDYRYLQks1nAW+8+frrr3fbTp061a0fP37crW/bts2tp+a7F5E6RuTo0aO5teeee85tmzr+YOvWrW592rRpbt1bCrtRp5nWll0kCIVdJAiFXSQIhV0kCIVdJAiFXSQIhV0kCI2znwUmT56cW7vjjjsK3fZnn33m1t988023/vXXXxe6/0ZJnXN+7Nixbj01l/7cc89161deeWVu7e2333bb1noOiuSWneSTJA+Q3DXsukkkN5J8L7ucWNO9i0hpRrMb/zSAW0677gEAm8zsCgCbsp9FpIklw25mWwCcvobQEgBrsu/XALitzv0SkTqr9T37JWbWBwBm1kfy4rxfJNkFIP9EZCJSioZ/QGdmqwGsBnTCSZEq1Tr09jHJDgDILv3lNkWkcrWG/SUAy7LvlwF4sT7dEZFGSe7Gk3wewAIAk0n2AvgVgIcA/I7kPQD2AfhpIzspvlWrVuXW5s2b57ZNjYOnxtk/+OADt97f3+/Wq5Iaqz5y5Eih20+Nw69cuTK3dv/997ttd+/enVvzHlcy7Ga2NKf0w1RbEWkeOlxWJAiFXSQIhV0kCIVdJAiFXSSI0qe4trTkv76kph2erbylhQHgkUcecesLFy7MraWG1tavX+/WH3jAn+OUWna5Wf+mqSms11xzTaHbb21tdeu33HL63LL/d/PNN7tt9+/fn1u79dZbc2vasosEobCLBKGwiwShsIsEobCLBKGwiwShsIsEoVNJlyA1prtlyxa3PmPGDLfuTSP96KOP3LbPPPOMW+/r63PrVY6jt7e3u/U5c+bk1pYvX+629ZZUBtLj6CneFNjU9FjvuAzvOBZt2UWCUNhFglDYRYJQ2EWCUNhFglDYRYJQ2EWCKHWcnaS7lO2xY8dK7M2Z8cZVZ8+e7bZdsWKFW+/s7HTrx48fd+uffPJJbm3t2rVu2127drn1gYEBt16ENyYMABdeeKFbf+KJJ9z6DTfckFsbN26c2za15HJR27dvz63de++9btvu7u6a7lNbdpEgFHaRIBR2kSAUdpEgFHaRIBR2kSAUdpEgSh1nb2trw4QJE3LrVY6zp87dPn369Nza448/7radMmWKW0/Ny/7888/d+lNPPZVb27Bhg9v26NGjbn3ixIlufcyYMW7dW0I4dX70BQsWuHXv3OsAcPLkydza+PHj3bapOeUpqfP1L1myJLfW29tb6L7zJLfsJJ8keYDkrmHXPUjyQ5I7sq9FDemdiNTNaHbjnwYw0kvoP5nZ7OxrXX27JSL1lgy7mW0BcLCEvohIAxX5gG4FyXey3fzcN3Yku0h2k+xu1nW/RCKoNeyPApgGYDaAPgC/zvtFM1ttZnPNbG5q4oOINE5N6TOzj81swMwGATwOYF59uyUi9VZT2El2DPvxJwD8eZIiUrnkODvJ5wEsADCZZC+AXwFYQHI2AAPQA8CfgDuMNy+8yNhm6jze3vg+ADz88MNu3RsXTc19To1lp84bf+jQIbf+7LPP5tYOHz7stp01a5Zb37hxo1tPnV/9xIkTubXUWPT555/v1lNvC73PiFL/a6m6d/wAALz22mtu/cMPP3TrjZAMu5ktHeFq/6wBItJ09ImZSBAKu0gQCrtIEAq7SBAKu0gQpU5xbW1tdYdTUsMZntSUxRtvvNGt33XXXW49NZXTk1qy+brrrnPrqWHFdevy5yGlpg17w3ZAemgtxWufek6LTjNt5BGbqeHU1FLYRf7Xa6Utu0gQCrtIEAq7SBAKu0gQCrtIEAq7SBAKu0gQpY6zDw4OJqc11ip1u6lTRafGsotoa/Of5tTpmlPLJq9atSq3lnpcRY4fKKroOHojeaehBoDNmze79Zdffrme3akLbdlFglDYRYJQ2EWCUNhFglDYRYJQ2EWCUNhFgih9nP2rr75qyG2nxqJ37Njh1lPj9OPGjcutFR0vTrVPjdOnTrks35QaR08tk33fffcVal8FbdlFglDYRYJQ2EWCUNhFglDYRYJQ2EWCUNhFgih1nH1gYKBh44+pcdOenh63/vrrr7v1BQsW5NZSSzZL80kd25Ba6vqqq65y6/v27XPrTXneeJKdJDeT3ENyN8mfZ9dPIrmR5HvZpX8GBhGp1Gh2408C+FszuwrAXwBYTnIGgAcAbDKzKwBsyn4WkSaVDLuZ9ZnZ9uz7LwHsATAVwBIAa7JfWwPgtkZ1UkSKO6P37CQvB/B9AG8BuMTM+oChFwSSF+e06QLQVaybIlLUqMNO8nwAawH8wsy+GO3kDzNbDWA1ALS0tJT/qYSIABjl0BvJMRgK+rNm9kJ29cckO7J6B4ADjemiiNRDcsvOoU34EwD2mNlvhpVeArAMwEPZ5YsN6WGdpKawLl682K3PmTMnt7ZmzZrcGgBMmTLFrU+aNMmtS/319fW59d7eXreeWoa7iqG1lNHsxs8HcBeAnSRPTQr/JYZC/juS9wDYB+CnjemiiNRDMuxm9u8A8t6g/7C+3RGRRtHhsiJBKOwiQSjsIkEo7CJBKOwiQbDM8cC2tja74IILcuuHDh0qrS/N5Oqrr3brW7Zscevt7e25tdRUy7Vr1xa673Xr1rl17/8rtYz2zJkz3fpll13m1t99992a26aOy3jrrbfcen9/v1tvJDMbcfRMW3aRIBR2kSAUdpEgFHaRIBR2kSAUdpEgFHaRIEodZ29paTFvHvCxY8dK68u3SUuL/5pc5G/YjPOuy5B6TlMGBwfr1JP60zi7SHAKu0gQCrtIEAq7SBAKu0gQCrtIEAq7SBCljrOTNG98s5nHLkW+LTTOLhKcwi4ShMIuEoTCLhKEwi4ShMIuEoTCLhJEMuwkO0luJrmH5G6SP8+uf5DkhyR3ZF+LRnOHg4ODuV8i0jjJg2pIdgDoMLPtJNsBbANwG4C/BnDEzP5x1HdGxjxTgkiJ8g6qGc367H0A+rLvvyS5B8DU+nZPRBrtjN6zk7wcwPcBnFr7ZgXJd0g+SXJiTpsukt0kuwv1VEQKGfWx8STPB/AagJVm9gLJSwB8CsAA/D2GdvX/JnEb2o0XabC83fhRhZ3kGAB/ALDezH4zQv1yAH8wM3clPoVdpPFqnghDkgCeALBneNCzD+5O+QmAXUU7KSKNM5pP438A4HUAOwGcGh/7JYClAGZjaDe+B8C92Yd53m1piqtIgxXaja8XhV2k8TSfXSQ4hV0kCIVdJAiFXSQIhV0kCIVdJIjkRJh6GzpGR0TKpi27SBAKu0gQCrtIEAq7SBAKu0gQCrtIEAq7SBBlj7N/OjAw8D/Dfp6MoVNbNaNm7Vuz9gtQ32pVz779WV6h1Pns37hzstvM5lbWAUez9q1Z+wWob7Uqq2/ajRcJQmEXCaLqsK+u+P49zdq3Zu0XoL7VqpS+VfqeXUTKU/WWXURKorCLBFFJ2EneQvK/SL5P8oEq+pCHZA/Jndky1JWuT5etoXeA5K5h100iuZHke9nliGvsVdS3mpbxbkDf8pYZr/S5q/fy52d8/2W/ZyfZCuBdAD8C0AtgK4ClZvYfpXYkB8keAHPNrPIDMEj+JYAjAP7t1NJaJP8BwEEzeyh7oZxoZvc3Sd8exBku492gvuUtM343Knzu6rn8eS2q2LLPA/C+me01sxMAfgtgSQX9aHpmtgXAwdOuXgJgTfb9Ggz9s5Qup29Nwcz6zGx79v2XAE4tM17pc+f0qxRVhH0qgD8O+7kXzbXeuwHYQHIbya6qOzOCS04ts5VdXlxxf06XXMa7TKctM940z10ty58XVUXYRzoJXTON/803sz8H8GMAy7PdVRmdRwFMw9AagH0Afl1lZ7JlxtcC+IWZfVFlX4YboV+lPG9VhL0XQOewn78DYH8F/RiRme3PLg8A+D2G3nY0k49PraCbXR6ouD//x8w+NrMBMxsE8DgqfO6yZcbXAnjWzF7Irq78uRupX2U9b1WEfSuAK0h+l+Q5AH4G4KUK+vENJMdnH5yA5HgAC9F8S1G/BGBZ9v0yAC9W2Jc/0SzLeOctM46Kn7vKlz83s9K/ACzC0Cfy/w3g76roQ06/vgfg7exrd9V9A/A8hnbr+jG0R3QPgIsAbALwXnY5qYn69gyGlvZ+B0PB6qiobz/A0FvDdwDsyL4WVf3cOf0q5XnT4bIiQegIOpEgFHaRIBR2kSAUdpEgFHaRIBR2kSAUdpEg/hfZ2HH4WU3EkAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(tf.reshape(generator(np.random.randn(1,100)),(28,28)),cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000015E1DEFC168> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.estimator'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000015E1DEFC168> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.estimator'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000015E1DEFC168> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000015E1E167048> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.estimator'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000015E1E167048> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.estimator'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000015E1E167048> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000015E1E167F78> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.estimator'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000015E1E167F78> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.estimator'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000015E1E167F78> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000015E1E2E83A8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.estimator'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000015E1E2E83A8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.estimator'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000015E1E2E83A8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000015E1E2E8EE8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.estimator'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000015E1E2E8EE8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.estimator'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000015E1E2E8EE8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000015E1E34DDC8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.estimator'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000015E1E34DDC8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.estimator'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000015E1E34DDC8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000015E1E381D38> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.estimator'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000015E1E381D38> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.estimator'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000015E1E381D38> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000015E1E4EDCA8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.estimator'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000015E1E4EDCA8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.estimator'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000015E1E4EDCA8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000015E1E54B828> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.estimator'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000015E1E54B828> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.estimator'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000015E1E54B828> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000015E1E563708> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.estimator'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000015E1E563708> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.estimator'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000015E1E563708> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000015E1E608678> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.estimator'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000015E1E608678> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.estimator'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000015E1E608678> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000015E1DE1EF78> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.estimator'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000015E1DE1EF78> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.estimator'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000015E1DE1EF78> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000015E1E704438> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.estimator'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000015E1E704438> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.estimator'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000015E1E704438> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000015E1E74DD38> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.estimator'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000015E1E74DD38> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.estimator'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000015E1E74DD38> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000015E1E76F8B8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.estimator'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000015E1E76F8B8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.estimator'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000015E1E76F8B8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000015E1E7879D8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.estimator'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000015E1E7879D8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.estimator'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000015E1E7879D8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000015E1E7F2558> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.estimator'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000015E1E7F2558> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.estimator'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000015E1E7F2558> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000015E1E8380D8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.estimator'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000015E1E8380D8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.estimator'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000015E1E8380D8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000015E1E838C18> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.estimator'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000015E1E838C18> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.estimator'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000015E1E838C18> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000015E1E85FD38> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.estimator'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000015E1E85FD38> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.estimator'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000015E1E85FD38> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000015E1E8C08B8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.estimator'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000015E1E8C08B8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.estimator'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000015E1E8C08B8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000015E1E8DA9D8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.estimator'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000015E1E8DA9D8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.estimator'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000015E1E8DA9D8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000015E1E94B558> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.estimator'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000015E1E94B558> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.estimator'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000015E1E94B558> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000015E1E74D3A8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.estimator'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000015E1E74D3A8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.estimator'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000015E1E74D3A8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000015E1E9AE828> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.estimator'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000015E1E9AE828> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.estimator'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000015E1E9AE828> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING:tensorflow:Entity <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000015E1E6A3678> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.estimator'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000015E1E6A3678> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.estimator'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000015E1E6A3678> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000015E1EC39678> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.estimator'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000015E1EC39678> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.estimator'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000015E1EC39678> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING:tensorflow:From C:\\Users\\Sourabh\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Sourabh\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/Sourabh/Deep Neural Network/Gans\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/Sourabh/Deep Neural Network/Gans\\assets\n"
     ]
    }
   ],
   "source": [
    "generator.save(\"C:/Users/Sourabh/Deep Neural Network/Gans\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
